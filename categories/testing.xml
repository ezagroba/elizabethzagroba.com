<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Elizabeth Zagroba: Software Tester (Posts about testing)</title><link>https://elizabethzagroba.com/</link><description></description><atom:link href="https://elizabethzagroba.com/categories/testing.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>¬© 2021 &lt;a href="mailto:me@elizabethzagroba.com"&gt;Elizabeth Zagroba&lt;/a&gt; Mozilla Public License 2.0</copyright><lastBuildDate>Sat, 02 Jan 2021 10:33:48 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>The Anatomy of Two Exploratory Testing Sessions</title><link>https://elizabethzagroba.com/posts/2020/2020-12-26_anatomy_of_two_exploratory_testing_sessions/</link><dc:creator>Elizabeth Zagroba</dc:creator><description>&lt;figure&gt;&lt;img src="https://elizabethzagroba.com/images/posts/2020/success.png"&gt;&lt;/figure&gt; &lt;div&gt;&lt;p&gt;The &lt;a href="https://exploratorytesting.org/"&gt;Exploratory Testing Peer Conference&lt;/a&gt; &lt;a href="https://twitter.com/search?q=%23et19&amp;amp;src=typed_query"&gt;#ET19&lt;/a&gt; followed the 2019 Valencia edition of the European Testing Conference. I said something that I pretty immediately forgot in the upheaval when I returned to the office, but it really stuck with &lt;a href="https://twitter.com/charrett"&gt;Anne-Marie Charrett&lt;/a&gt;. I appreciate both that she remembered this at all, and continues to insist that I'm the one who had this stroke of genius when she really brought it to life. Here's the idea: &lt;/p&gt;
&lt;p&gt;It's straightforward to follow one thread or idea through an exploratory testing session. It's not straightforward to decide which path to take, feed information from one path back into another, recognize that there are different paths, or bring others along for this journey. &lt;/p&gt;
&lt;h4&gt;The Ensemble at Work&lt;/h4&gt;
&lt;p&gt;We have a weekly ensemble testing session at my workplace. For an hour and a half, testers from different teams working in the same tech stack come together to share knowledge and build testing skills. In a recent ensemble testing session, a tester on one team brought a ticket they'd been avoiding tackling on their own. They knew they didn't know how to test the fix. But they felt like they'd talked about it enough as a team that they should have understood what to do already. &lt;/p&gt;
&lt;p&gt;We read through the story with the group of testers. We determined that a static code analysis security scan had discovered vulnerabilities in a couple of libraries. The developers had fixed the issue by removing the libraries. It was our mission to make sure those libraries were removed. &lt;/p&gt;
&lt;p&gt;Immediately a plan came to my mind:
1. Map out what kinds of pages there were, assuming that different pages of the same type would be likely to load the same libraries: list view, detail view, landing page, etc. 
1. Look at one of each of those pages with the Network tab open in the developer tools.&lt;/p&gt;
&lt;p&gt;In a quick spirt of excitement, I dumped this idea on the group without figuring out if people knew what either of these things meant. (It turns out, not everyone did.) But everyone seemed to understand that there was somewhere in the developer tools where we could tell which libraries were loaded, so we started there. Exploring in a group is not about getting everyone to follow my idea immediately (or ever), it's about making sure everyone is on board and understands what's going on.&lt;/p&gt;
&lt;p&gt;Proving the absence of a thing is harder than proving the presence of something, so we spent a bit of time looking through the Console and Storage tabs, as well as reloading the page with the Network tab opened, to figure out what appeared where. That helped everyone remember or discover that we didn't need to reload the page if the Network tab was open before the page loaded. This sped us up for the rest of the session.&lt;/p&gt;
&lt;p&gt;Next, we looked at a couple of similar-looking list pages. We searched for the libraries in the Network tab. They weren't there. Now that we'd seen a couple of examples, I decided it was the right time to bring up my original idea of grouping pages by type. (Going from the abstract to the concrete doesn't work for everybody, so sometimes going from the concrete to the abstract works better.) I asked "These last two pages both looked like list pages, what other kinds of pages are there? Can we list them? Should we look at a detail page?" This comment blew the mind of the tester who brought this ticket. They'd been testing this product for two years and had never organized the product this way in their brain. It may not have occurred to them that a product &lt;em&gt;could&lt;/em&gt; be organized in different ways in their thoughts depending on the circumstance. We got as part as listing the concrete pages we'd checked, but not as far as identifying all the types in the abstract before the energy in the ensemble moved on.&lt;/p&gt;
&lt;p&gt;We looked at a detail page. We looked at a settings page. Then one of the testers who's been looking at a lot of front-end Javascript noticed two things: both the URLs we were searching for had &lt;code&gt;ajax&lt;/code&gt; in them, so we only needed to search for one thing on each page we opened. And second, they knew that ajax was used to make changes to pages that had already loaded, so they asked "what kinds of pages change after they're loaded?" In this particular application, it was mostly forms in pop-up windows, so we concentrated our efforts there for the rest of the session. &lt;/p&gt;
&lt;p&gt;The whole session took about an hour and a half. A tester that came in scared and confused left empowered, with information to bring to their developers, and  a plan for how to execute the rest of the testing. Here's one way of looking at our exploratory testing session:&lt;/p&gt;
&lt;p&gt;&lt;a href="https://elizabethzagroba.com/images/posts/2020/work-ensemble.png"&gt;&lt;img src="https://elizabethzagroba.com/images/posts/2020/work-ensemble.png"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;At every stage, we absorbed a lesson as a group, and used it as our new superpower to make our testing better for the next bit. There were other paths we could have pursued, but many of these weren't consciously mentioned or acknowledged during the session.&lt;/p&gt;
&lt;h4&gt;The Ensemble at the Conference&lt;/h4&gt;
&lt;p&gt;I facilitated a couple of ensemble sessions with groups at Agile Testing Days. Our first emsemble had a couple people drop out, so it ended up being one tester, one developer, and me. We were looking at a &lt;a href="https://eviltester.github.io/TestingApp/apps/7charval/simple7charvalidation.htm"&gt;very straightforward application&lt;/a&gt; from Alan Richardson where you can decide whether a string contains 7 characters and is valid (in the set A-Z, a-z, 0-9, and * ). A few different times the developer and I asked if we should look at the source code. Rather than trying to interrogate the application based on the behavior from different inputs (black box testing), we wanted to go to the source (white box testing). &lt;/p&gt;
&lt;p&gt;But we never did. We kept trying different inputs, getting increasingly creative with order, special characters, Unicode characters, other languages as we progressed. But we never chose a different path. Even as I tried to encourage us to take notes so we wouldn't try the same things we'd already tried, we didn't. &lt;/p&gt;
&lt;p&gt;&lt;a href="https://elizabethzagroba.com/images/posts/2020/atd-ensemble.png"&gt;&lt;img src="https://elizabethzagroba.com/images/posts/2020/atd-ensemble.png"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;We did manage to find a good resource for copying and pasting unicode characters, but we didn't learn how to explore the application more efficiently, or take what we learned earlier in the session to apply it to the rest of the session.&lt;/p&gt;
&lt;h4&gt;The Power of Exploratory Testing&lt;/h4&gt;
&lt;p&gt;Brute force will get you somewhere. Trying enough different inputs, or different pages, and you'll gather more information about how the application works. But the power of exploratory testing comes from learning from your earlier results. It's realizing there are different ways to go, different paths to follow, jumping on one of those while it serves you, and making sure everyone else is along for the ride. &lt;/p&gt;&lt;/div&gt;</description><category>exploratory-testing</category><category>teaching</category><category>testing</category><guid>https://elizabethzagroba.com/posts/2020/2020-12-26_anatomy_of_two_exploratory_testing_sessions/</guid><pubDate>Fri, 25 Dec 2020 23:00:00 GMT</pubDate></item><item><title>Agile Testing Days 2020</title><link>https://elizabethzagroba.com/posts/2020/2020-11-29_agile_testing_days_2020/</link><dc:creator>Elizabeth Zagroba</dc:creator><description>&lt;div&gt;&lt;p&gt;When you say no to what you don't have the energy for, you leave your time, attention, and devotion free to pursue what keeps you energized. Through a tumult of plans and dreams that only 2020 could continue to crush, the Agile Testing Days crew put on a revitalizing conference. I only caught a glimpse of the preparation that went into providing a top-notch experience for speakers and participants, and I have to commend the group on their commitment to the cause. Bravo.&lt;/p&gt;
&lt;p&gt;The talks were recorded. I've decided to cut myself off on catching up on missed talks after two weeks. Reflecting on what wisdom I've garned from a small subset of the offerings at Agile Testing Days will be more valuable than being exposed to every last word. In that spirit, let me give you a few takeaways in place of an exhaustive recap or analysis. &lt;/p&gt;
&lt;p&gt;Parveen Khan: watch this if you're looking to collaborate&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It is in doing the work that we discover what we must do. &lt;/li&gt;
&lt;li&gt;Don't get stuck when learning something alone; pair. &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Jo√£o Proen√ßa: watch this if you need a different direction&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Performing a health check and making a diagnosis are different skills. &lt;/li&gt;
&lt;li&gt;What barriers do we set for ourselves?&lt;/li&gt;
&lt;li&gt;The product is all the pieces the customers see, including the cloud infrastructure (and whatever else your team isn't responsible for). &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Paul Holland &amp;amp; Huib Schoots: watch this if your automation isn't providing valuable information&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The sunk cost fallacy means we're unlikely to get rid of automation code, even if it's ineffective.&lt;/li&gt;
&lt;li&gt;We often fail at getting people to change.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Gitte Kligaard talk: watch this if you've been hiding your true self at work&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;"I'm just going to rewind." (Possibly my favorite takeaway from this conference, I'm going to use this anytime I trip over my words.)&lt;/li&gt;
&lt;li&gt;Creativity comes when inspired by others.&lt;/li&gt;
&lt;li&gt;Being professional is knowing your craft, and admitting when you don't know.&lt;/li&gt;
&lt;li&gt;Spend time with yourself to listen to yourself.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Alex Schladebeck &amp;amp; Ashley Hunsberger: no recording, but follow these ladies on Twitter for how to balance life and leadership&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Tell people what you want. They may be able to help you.&lt;/li&gt;
&lt;li&gt;Have a clear vision of what you want.&lt;/li&gt;
&lt;li&gt;Write down your fear. Ask yourself: Why is this positive? How can I build the courage to do this?&lt;/li&gt;
&lt;li&gt;Be explicit about what you're doing.&lt;/li&gt;
&lt;li&gt;Show how you're working.&lt;/li&gt;
&lt;li&gt;Build a practice of reflection.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Angie Jones: watch this if you need a push to get into automation&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Determine your goal first. If you don't know it, you'll definitely fail.&lt;/li&gt;
&lt;li&gt;When you're a leader, celebrate the small victories. &lt;/li&gt;
&lt;li&gt;There's no reason to shame people for being creative and doing the best they can.&lt;/li&gt;
&lt;li&gt;It's not realistic to assume master level by default.&lt;/li&gt;
&lt;li&gt;Find out why developers don't participate in automation.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Rob Meaney: watch this if you don't get why observability is important&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;We learn profound lessons from painful experiences.&lt;/li&gt;
&lt;li&gt;Build relationships. Influence people at the right time.&lt;/li&gt;
&lt;li&gt;Pain + reflection =&amp;gt; progress&lt;/li&gt;
&lt;li&gt;It doesn't matter how much we test a thing if nobody wants to use it.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Tobias Geyer: watch this if you're struggling with an ethical dilemna &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Could ethics be a non-functional requirement?&lt;/li&gt;
&lt;li&gt;Read the codes of ethics proposed by the IEEE, ISTQB, ACM, and James Bach.&lt;/li&gt;
&lt;li&gt;A hippocrattic oath for software testing: avoid harm.&lt;/li&gt;
&lt;li&gt;Promote environment sustainability.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Smita Mishra: watch this if you're interviewing users &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Listen to be able to ask clarifying questions and dig deeper. &lt;/li&gt;
&lt;li&gt;Ask users: their objective, what they found, about the impact, where they're struggling, what could make their lives easier.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Eveline Moolenaars: watch this if you're learning to coach&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;"We have a policy; it's somewhere on the internet" isn't enough.&lt;/li&gt;
&lt;li&gt;"Everyone deserves a coach to make them aware of what they've forgotten." ~Brad Gilbert&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Federico Toledo: watch this if you or those around you are losing steam&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A tester with a sense of purpose is more resilient.&lt;/li&gt;
&lt;li&gt;Focus on strengths more than weaknesses, turning up the good. &lt;/li&gt;
&lt;li&gt;Provide visibility that you're doing something with the feedback.&lt;/li&gt;
&lt;li&gt;Ask people if they're getting what they need.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Nicola Sedgwick: watch this if you're the gatekeeper for quality&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Do not correlate your own successes with the quality of the entire system.&lt;/li&gt;
&lt;li&gt;Contract-driven work is not holistic quality.&lt;/li&gt;
&lt;li&gt;Report when there has been no progress.&lt;/li&gt;
&lt;li&gt;Ask for a code walk-through before a build is ready.&lt;/li&gt;
&lt;li&gt;Shift quality left all the way to the executive team.&lt;/li&gt;
&lt;li&gt;Testers were hoarding responsibility for quality. Let it go.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Joep Schuurkes: watch this if (or while) you're stuck in an ineffective meeting&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ask yourself: is my work inside or outside of meetings?&lt;/li&gt;
&lt;li&gt;Get the right group of people in the room before holding a meeting.&lt;/li&gt;
&lt;li&gt;Express specific appreciations for things done well so people will keep doing them.&lt;/li&gt;
&lt;li&gt;Meetings are synchornous collaboration with a purpose.&lt;/li&gt;
&lt;li&gt;Standups should remove impediments.&lt;/li&gt;
&lt;li&gt;The metaphors we choose say something about how we feel about our work.&lt;/li&gt;
&lt;li&gt;Leadership is creating an environment where everyone can contribute to solving a problem. ~Jerry Weinberg&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Clare Norman: watch this if you're truly stuck&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Quality is everyone's care.&lt;/li&gt;
&lt;li&gt;"Success is liking who you are, what you do, and how you do it." ~Maya Angelou&lt;/li&gt;
&lt;li&gt;Your courage quota for the day might vary. &lt;/li&gt;
&lt;li&gt;You don't get better by doing the same thing everyday. &lt;/li&gt;
&lt;li&gt;I didn't know how I needed to be helped.&lt;/li&gt;
&lt;li&gt;You can't drag someone through time.&lt;/li&gt;
&lt;li&gt;We live far less in the present than we ought to.&lt;/li&gt;
&lt;li&gt;How magical is it when people value the change that you're making?&lt;/li&gt;
&lt;li&gt;Passion spreads when other people share in your excitement.&lt;/li&gt;
&lt;li&gt;Have a cheerleader in your life.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class="img_container" style="display: inline-block;"&gt;&lt;img alt="" src="https://elizabethzagroba.com/images/posts/2020/success.png" style="display:block; margin-left: auto; margin-right: auto;" title="Clare Norman channeling Maya Angelou on success"&gt;&lt;span class="img_caption" style="display: block; text-align: center;"&gt;Clare Norman channeling Maya Angelou on success&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Jenny Bramble: watch this if your tests are failing on expected behavior&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Many defects I filed are never fixed. Unfixed defects become expected behavior.&lt;/li&gt;
&lt;li&gt;Automation has never found a defect. Automation tells us behavior has changed. &lt;/li&gt;
&lt;li&gt;Tests should pass on expected behavior, including some defects.&lt;/li&gt;
&lt;li&gt;Document your tests for others, including your future self.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;James Lyndsay &amp;amp; Anne Colder: watch this if you feel like an impostor &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Acknowledge when you can't help.&lt;/li&gt;
&lt;li&gt;If you could take one step forward, what would you do?&lt;/li&gt;
&lt;li&gt;Talk to your person, or ask a smaller group of people if they have an answer to your problem. &lt;/li&gt;
&lt;li&gt;Forgiveness is one of the most powerful things you can do as a human being.&lt;/li&gt;
&lt;li&gt;After you make a mistake: wallow in it (really feel it first), forgive yourself, then dance.&lt;/li&gt;
&lt;li&gt;Your job title allows other people to figure out how to work with you.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Gitte Klitgaard AMA: watch this if you miss the hallway track&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Listen to hear what's being said, not to respond. &lt;/li&gt;
&lt;li&gt;We can't read minds.&lt;/li&gt;
&lt;li&gt;Creating a safe space allows you to feel uncomfortable. &lt;/li&gt;
&lt;li&gt;Silence is a tool. &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Sophie K√ºster: watch this if you're ready to tell your colleagues your big secret&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;There is strength in showing vulnerability.&lt;/li&gt;
&lt;li&gt;People want to help you. Let them. &lt;/li&gt;
&lt;li&gt;Ask yourself: how am I treating myself?&lt;/li&gt;
&lt;li&gt;Anything worth doing is worth doing poorly. Poorly done is better than not done at all. &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Gitte Klitgaard &amp;amp; Morgan Ahlstr√∂m: watch this if you want to get psychological safety in the boardroom and on the roadmap&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Make time to address psychological safety. Put it on the same level in your team's goals as your product goals. &lt;/li&gt;
&lt;li&gt;We are role models. We lead by example.&lt;/li&gt;
&lt;li&gt;More people were uncomfortable giving than receiving code reviews. &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Ard Kramer: watch this if you're getting burned out&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Humans have an unrealitic belief in our own influence. &lt;/li&gt;
&lt;li&gt;Performing your testing role doesn't make you popular. &lt;/li&gt;
&lt;li&gt;Most people looking for confirmation that the software is working. To form a logical proof, we look for evidence that the software doesn't work. &lt;/li&gt;
&lt;li&gt;Ask yourself: which circumstances could I control? Did I manage expectations correctly? &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I'm grateful I got to connect with people who keep me going. I'm grateful Agile Testing Days tried to make this work in person. I'm grateful I was able to drop my workshop instead of abaondoning people in breakout rooms to do something they've never done before. I'm grateful the mobbing session I helped organize and facilitate went smoothly. I'm grateful that my job allows me the time and space to be rejunivated by this all. I'm grateful. üôè&lt;/p&gt;&lt;/div&gt;</description><category>agile-testing-days</category><category>conference</category><category>testing</category><guid>https://elizabethzagroba.com/posts/2020/2020-11-29_agile_testing_days_2020/</guid><pubDate>Sat, 28 Nov 2020 23:00:00 GMT</pubDate></item><item><title>Finding relevant search results</title><link>https://elizabethzagroba.com/posts/2020/2020-09-21_finding_relevant_search_results/</link><dc:creator>Elizabeth Zagroba</dc:creator><description>&lt;div&gt;&lt;p&gt;In his crafting time, one of our developers decided to fine-tune our search results. He added relevancy scoring to give weights to different text fields. It was my job to determine if the right results were turning up at the top of the list of search results. So I had to ponder: what made a search result relevant? &lt;/p&gt;
&lt;p&gt;First, I realized that feedback from our users is the best way to answer this question. Anything I could do to get this feature out into production, where we'd get real data about what people searched for, would be more valuable that brainstorming test cases for this feature. I set myself a timebox of two and a half hours, the rest of the afternoon on a day in a week filled with competing priorities. We'd agreed as a team ahead of time that I could determine the testing approach, and our product owner would decide what was or wasn't worth fixing before this feature went out. &lt;/p&gt;
&lt;p&gt;I saved the first 45 minutes of my timebox to research what people had to say about search relevancy. Surely I was not the first person contemplating this problem. Over on the Ministry of Testing Club forum, I found what seemed to be a promising title of a post. &lt;a href="https://club.ministryoftesting.com/t/how-would-you-test-a-search-api/28027"&gt;It turned out a past Elizabeth from a year ago wrote it, and nobody had answered it satisfactorily in the intervening time&lt;/a&gt;. ü§¶‚Äç‚ôÄÔ∏è&lt;/p&gt;
&lt;p&gt;After Duck-Duck-Go-ing some actual answers, I found a couple of resources from websites I've trusted and found fruitful in the past: &lt;a href="https://alistapart.com/article/testing-search-for-relevancy-and-precision/"&gt;A List Apart&lt;/a&gt; and &lt;a href="https://www.philosophe.com/archived_content/search_topics/search_tests.html"&gt;philosophe.com&lt;/a&gt;. A List Apart suggested honing in on a specific intent, searching for the queries users seek most frequently, and seeing how far those items fall from the top in the search results. The philosophe guidance about testing search gave me something deeper to consider: users shouldn't have to ponder the reasoning behind the search results. That was enough for me to develop some test cases. &lt;/p&gt;
&lt;p&gt;As I searched and adjusted the weights of various fields, plenty of normal things happened: setting the relevancy values to zero meant the result wasn't listed, multiple instances of the same word counted more than a single instance, and giving fields stronger weights caused their results to move up in the rankings. But as a bug magnet, I uncovered things that were both interesting to discover and outside the original scope of the story. &lt;/p&gt;
&lt;p&gt;&lt;span class="img_container" style="display: inline-block;"&gt;&lt;img alt="" src="https://elizabethzagroba.com/images/posts/2020/log-of-zero.png" style="display:block; margin-left: auto; margin-right: auto;" title="Log of zero is negative infinity"&gt;&lt;span class="img_caption" style="display: block; text-align: center;"&gt;Log of zero is negative infinity&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h4&gt;Bugs&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;I opted to edit data that was already in our test environment rather than setting up completely new data. In doing so, I discovered a couple description fields that were missing an indexing update in the search results when edited through the UI. &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;I tried to use the default values for everything to see "normal" results. One field was going to add a value to the relevancy rating, so zero seemed like it should be the default option. Unfortunately a couple of the options for the weighting feature transformed the value using the &lt;code&gt;log&lt;/code&gt; and &lt;code&gt;ln&lt;/code&gt; (natural log) functions, which are undefined at zero. All my search results disappeared. &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;I looked at the data that was already in the database, and used a search term that showed up a lot already. It turned up nothing. I searched for part of the word. That turned up all the results I was expecting. I realized the search term was indexed separately because of the characters we used to break the word apart. Imagine having a bunch of &lt;code&gt;sun-bleached&lt;/code&gt; items, but you can only find them if you search for &lt;code&gt;sun&lt;/code&gt; or &lt;code&gt;bleached&lt;/code&gt;, not &lt;code&gt;sun-bleached&lt;/code&gt;. &lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Bug 1 the developer agreed was a bug, and we fixed as part of the story. Bug 2 was "working as expected" from a developer point-of-view, but seemed a little weird to the product owner. We meant to look into as part of the story and decide if we should eliminate the log functions as options entirely, but other priorities came crashing down upon before we could. It's out on production to the handful of internal users with access to the relevancy tuning. Bug 3 we added to the backlog, and I hope someday a swarm of user complaints make it a priority for us. &lt;/p&gt;
&lt;h4&gt;Morals&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;Users know best.&lt;/li&gt;
&lt;li&gt;Someone else on the internet has had your problem before. &lt;/li&gt;
&lt;li&gt;Report information that matters.&lt;/li&gt;
&lt;li&gt;When the risk is low, let it go. &lt;/li&gt;
&lt;/ol&gt;&lt;/div&gt;</description><category>exploratory-testing</category><category>risk-based-testing</category><category>search</category><category>testing</category><guid>https://elizabethzagroba.com/posts/2020/2020-09-21_finding_relevant_search_results/</guid><pubDate>Sun, 20 Sep 2020 22:00:00 GMT</pubDate></item><item><title>SoCraTes UK, August 2020</title><link>https://elizabethzagroba.com/posts/2020/2020-08-02_socrates-uk-august-2020/</link><dc:creator>Elizabeth Zagroba</dc:creator><description>&lt;div&gt;&lt;p&gt;After years of envying the tweets and stories from SoCraTes conferences, this curs√®d disease finally made attending one possible. I could afford the time (part of one day, instead of a whole weekend + travel) and the cost (¬£2.50, instead of ‚Ç¨‚Ç¨‚Ç¨). &lt;/p&gt;
&lt;p&gt;I'm preparing to host an open space of our own in September (&lt;a href="http://testcraftcamp.nl/"&gt;TestCraftCamp&lt;/a&gt;, tickets are free!), so aside from the sessions, I was also interested in the infrastructure of the event. The hosts hung out in one central Zoom room (a one-month subscription cost them ¬£10). Each attendee was appointed co-host, allowing us to move around among the many breakout rooms as we pleased. (There may have been as many breakout rooms as there were participants, named with varying levels of creativity but functionally the same.) A &lt;a href="https://www.notion.so/"&gt;Notion&lt;/a&gt; board captured the user-generated schedule, along with links to the &lt;a href="https://www.mural.co/"&gt;Mural&lt;/a&gt; whiteboards the organizers created for each room, rather than for each session. Chat happened in a &lt;a href="https://discord.com/"&gt;Discord&lt;/a&gt; channel, but &lt;a href="https://twitter.com/ezagroba/status/1287372791168278529"&gt;I wouldn't recommend it&lt;/a&gt;. &lt;/p&gt;
&lt;p&gt;The first session I attended was a discussion about the value and hazards of leaving a job. First: decide where you want to go, what kind of thing you're looking for. You're not going to get where you want to go by running away from your current role. Run &lt;em&gt;towards&lt;/em&gt; something. Have honest conversations with your peers, manager, mentor, coach, etc. about what change you can affect at the organization. (Things like the nature of the product, the tech stack, or the customer base are unlikely to change quickly.) If you do decide to change jobs, it will take a lot of energy to find something new and build your network at the new place. You may have to prove yourself all over again, and solve the problems you've already solved with this different group of people. &lt;/p&gt;
&lt;p&gt;After taking a total of three bullet points in my notebook, the host of the second session I attended about hypergrowth was having trouble taking notes and listening to/facilitating the session. I volunteered to jump in to take the notes. Here's what I made:&lt;/p&gt;
&lt;p&gt;&lt;span class="img_container" style="display: inline-block;"&gt;&lt;img alt="" src="https://elizabethzagroba.com/images/posts/2020/hypergrowth.png" style="display:block; margin-left: auto; margin-right: auto;" title="Notes from hypergrowth session"&gt;&lt;span class="img_caption" style="display: block; text-align: center;"&gt;Notes from hypergrowth session&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;I was trying to capture what people said, change the background colors, and move the notes around to put similar ideas next to each other. It was hard to know in the moment whether all of that is legible or helpful for anyone else. Luckily people in the session and in the Discord channel later thanked me for my work. I'm still struggling with how to impart any note-taking skill onto others, particularly when this can be seen as a gendered task.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Men: Wow, you are so good at taking notes!&lt;br&gt;
Me: You would be too if you got stuck being the one doing it all the time!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;But I digress, back to hypergrowth: The things that worked before COVID and at smaller orgs don't work at a bigger org today. Find your people within the smaller org - your department, your mentor, your friends - so you can feel stable even as things around you grow and change. Communicate your expectations clearly, for yourself and for your team. Keep a journal of what you've accomplished to feel more anchored in the value of your work. &lt;/p&gt;
&lt;p&gt;After lunch, I started off in the wrong room because I didn't notice the sessions had been moved, but found my way to the one about coaching your peers. The conversation floated from a definition of terms to how to make space for mentoring. In order for people to mentor, there must be consent from the mentee. Ideally there is also some expertise in the organization around what is good, and someone (mentor or not) to teach the mentee what is good. The conversation reminded me of a talk I saw from Marianne Duijst; &lt;a href="https://youtu.be/vXIZpe-x4o8?t=595"&gt;here's the moment she started talking about the difference between coaches, sponsors, teachers, and role models, and how they can support you in different ways&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Anytime Maaret Pyh√§j√§rvi is running an exploratory testing session, go to it. You will be better for it. This time, we tested a simple web application. We ended up spending most of the time adding scenarios to the automated tests Maaret had already set up in Robot framework. One of the questions it brought up for me: do you leave failed tests in your automation suite to highlight unexpected behavior? I had this problem this week: I'd updated a schema to validate against the current behavior while the story was in progress, instead of the behavior we wanted when it was done, so I could verify other fields in the output. Next time I think I'll separate them into two tests and leave them both as pending (marked as xfail in the pytest framework) so it's clear something needs to change before the software is released.&lt;/p&gt;
&lt;p&gt;Thank you for the SoCraTes organizers for, as I learned a coach does, holding this space for us to examine ourselves and reflect. As someone who is much more fluent in emoji than GIF, I'm grateful to have won the hearts of the participants with this "letting the cat out of the bag" GIF in the GIF challenge.&lt;/p&gt;
&lt;p&gt;&lt;span class="img_container" style="display: inline-block;"&gt;&lt;img alt="" src="https://media1.tenor.com/images/e49bc18b66056a71171ae6f16046a2a4/tenor.gif?itemid=11543319" style="display:block; margin-left: auto; margin-right: auto;" title="Cat aggressively jumping out of a backpack"&gt;&lt;span class="img_caption" style="display: block; text-align: center;"&gt;Cat aggressively jumping out of a backpack&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/div&gt;</description><category>conference</category><category>note-taking</category><category>testing</category><guid>https://elizabethzagroba.com/posts/2020/2020-08-02_socrates-uk-august-2020/</guid><pubDate>Sat, 01 Aug 2020 22:00:00 GMT</pubDate></item><item><title>TestBash Netherlands 2019</title><link>https://elizabethzagroba.com/posts/2020/2020-07-14_testbash_netherlands_2019/</link><dc:creator>Elizabeth Zagroba</dc:creator><description>&lt;div&gt;&lt;p&gt;In reviewing my notes from the TestBash Netherlands that occurred in May of 2019, two big, related themes jump out at me: &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;keep exploratory testing&lt;/li&gt;
&lt;li&gt;learn by sharing&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Andy Brown gave a talk about human factors in highly automated systems. As flying airplanes becomes more automated, pilots know less about how to switch to manual overrides in a time of crisis. You might not have more than a few hours a year of practice for when things go down. Continuing to share stories from the past and learn from them is one way out.&lt;/p&gt;
&lt;p&gt;For &lt;a href="https://twitter.com/Godtesen"&gt;Gitte Ottosen&lt;/a&gt;, who gave us a tester's perspective on Agile, learning never ends. Understanding the customer journey and tying your work back to the business value are essential for making informed decisions about what to test, and which subset of those things to automate. Teaching, knowledge-sharing, coaching, and pairing can get the whole team involved in advancing quality, even if they're not all strong exploratory testers. &lt;/p&gt;
&lt;p&gt;&lt;a href="https://twitter.com/JitGo"&gt;Jit Gosai&lt;/a&gt; spoke about continuous testing. Practice test-driven development, story mapping, and three amigos meetings before the code is written. Improve automation test suites, use exploratory and mob testing, and incorporate feedback from the customer. When you're exploratory testing, you're not just confirming that the software functions as expected, you're testing the goal of your whole organization. Jit found that getting everybody on the team exploratory testing caught more bugs than automated tests. &lt;/p&gt;
&lt;p&gt;&lt;a href="https://twitter.com/MaritvanDijk77"&gt;Marit van Dijk&lt;/a&gt; hit the nail on the head with her talk: keep exploratory testing. Maintaining a consistent state of test data across mutliple teams is difficult. Rather than spend your time setting up control mechanisms for those systems, explore the systems themselves. Bugs are found not in the things we can control or know about, but in the space between systems. Pairing a developer with a tester was a lot faster than testing solo, because nobody had to go back and reproduce bugs. Spread the risk across systems by hooking them up one at a time.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://twitter.com/VeraGeBa"&gt;Vera Gehlen-Baum&lt;/a&gt; and &lt;a href="https://twitter.com/isleoftesting"&gt;Beren Van Daele&lt;/a&gt; spoke about incorporating your learning into your backlog. Identify what you want to learn, and write actionable acceptance criteria for your learning. This should include sharing what you've learned individually or with the team; it doesn't have to be confined to same sprint as the work for the team. Linking personal goals to business goals will ensure that people see they're improving.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://twitter.com/j19sch"&gt;Joep Schuurkes&lt;/a&gt; talked us through what he was thinking as he was live-coding, which is learning and sharing at the most granular level. Separate concerns when you automate: keep what the code is supposed to accomplish separate from how it's accomplishing it. He expanded the CRUD heuristic that helps me decide what to automate, and added an extra DERR to make it CRUDDERR to ensure you can also debug, explore, run, and report on your code. &lt;/p&gt;
&lt;p&gt;&lt;a href="https://twitter.com/Annosofie"&gt;Anne Colder&lt;/a&gt; and &lt;a href="https://twitter.com/VinWijNL"&gt;Vincent Wijnen&lt;/a&gt; gave an experience report about their mentor-mentee relationship. Mentoring is different from teaching. Ask questions about your mentee's experience, and expect different questions from them than you'd receive from your more experienced colleagues. Mentoring stimulates reflection on both sides. &lt;/p&gt;
&lt;p&gt;Drew Pontikis spoke about the illusion of control. Challenge your own thinking by listening to new voices. Recognize when you can affect change in a situation.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://twitter.com/QualityFrog"&gt;Ben Simo&lt;/a&gt; gave the last talk of the day about the art of scientific investigation. Design your next experiment based on your previous ones, and adapt as you go along. &lt;/p&gt;
&lt;p&gt;There was a whole slew of 99-second talks, but the only memorable and explicable thing I wrote down from them was something Ilena said: "Understand your team doesn't function the way that you do." &lt;/p&gt;
&lt;p&gt;The day prior to the day of talks, I helped facilitate and debrief a workshop that Joep Schuurkes developed around building an API testing framework. It was the first time we'd given it together, so that whole day was a 'learn by sharing' experience for me.&lt;/p&gt;&lt;/div&gt;</description><category>conference</category><category>testbash</category><category>testing</category><guid>https://elizabethzagroba.com/posts/2020/2020-07-14_testbash_netherlands_2019/</guid><pubDate>Mon, 13 Jul 2020 22:00:00 GMT</pubDate></item><item><title>Humans Conf, June 2020</title><link>https://elizabethzagroba.com/posts/2020/2020-07-12_humans_conf_june_2020/</link><dc:creator>Elizabeth Zagroba</dc:creator><description>&lt;div&gt;&lt;p&gt;I found Humans Conf on Twitter, and found myself in a position to attend when &lt;em&gt;gestures at the general state of the world&lt;/em&gt; moved it online. You can check out the output from the entire open space on the &lt;a href="https://www.notion.so/June-2nd-2020-Virtual-Open-Space-26d1d0595b4b4574baf647025f3be544"&gt;Notion page&lt;/a&gt;. It took place for a few hours on a Tuesday night. I discovered the energy it takes to listen and participate attentively in the evening affected my work for the following couple of days. I am only human!&lt;/p&gt;
&lt;p&gt;The first session I attended was about making diversity more inclusive, and hosted by &lt;a href="https://twitter.com/buggylina"&gt;Lina Zubyte&lt;/a&gt;. Due to the makeup of the participants, the conversation veered towards being a woman in tech. We spoke about incorrect assumptions, how we felt about particular language (especially &lt;code&gt;guys&lt;/code&gt;), and how much energy that drains from us all the time. I heard stories from other women that echoed situations from my experience. I recognized how telling a story from a memorably bad day helps others understand and connect. I pondered if there's a way to make people understand, without reliving everyday indignities. My takeaway from the conversation was clear: you get to decide how to spend your energy. There will be people whose minds need changing, but the energy you would expend making that happen wouldn't be worth it. Let those people who challenge the premises of the problem space fall off your radar, and invest in people where you can make a difference. &lt;/p&gt;
&lt;p&gt;For the second session, I started off in motivating interactions, hosted &lt;a href="https://twitter.com/innoviva"&gt;Maren Baermann&lt;/a&gt;. I truly enjoyed the model she introduced regarding &lt;a href="https://en.wikipedia.org/wiki/Self-determination_theory#Motivations"&gt;extrinsic vs. intrinsic motivation&lt;/a&gt;, and tying those to our &lt;a href="https://en.wikipedia.org/wiki/Self-determination_theory#Basic_needs_and_intrinsic_motivation"&gt;basic needs&lt;/a&gt;. But when the Zoom gods kicked me out of the free room, I took it as a sign to go search for a less interactive session where I could just listen. I landed in a session relating couples therapy to your team dynamics, hosted by &lt;a href="https://twitter.com/DariaDorda"&gt;Daria Dorda&lt;/a&gt;. The conversation covered some national stereotypes, how people get distracted from the real message, and how to get the necessary distance to engage with a topic. My takeaway here was: if you don't set boundaries, others will for you. Amen.&lt;/p&gt;
&lt;p&gt;I'm grateful to &lt;a href="https://twitter.com/benjamin"&gt;Benjamin Reitzammer&lt;/a&gt; who hosted the open space, and all the others who made it run smoothly. Seeing just a handful of familiar faces set me at ease. I'd never seen Zoom chat used effectively, but the rush of answers to the closing questions at the end of the evening gave me that warm &amp;amp; fuzzy feeling like I'd actually attended a conference in person. I needed that, so thank you. &lt;/p&gt;
&lt;p&gt;I don't think I can bring myself to join the next Humans Conf on Wednesday, 15 July. I've got a week off, and I need some time away from Zoom to be feeling more human. :)&lt;/p&gt;&lt;/div&gt;</description><category>conference</category><category>humans</category><category>testing</category><guid>https://elizabethzagroba.com/posts/2020/2020-07-12_humans_conf_june_2020/</guid><pubDate>Sun, 12 Jul 2020 22:00:00 GMT</pubDate></item><item><title>Test Automation Day 2018</title><link>https://elizabethzagroba.com/posts/2020/2020-07-13_test_automation_day_2018/</link><dc:creator>Elizabeth Zagroba</dc:creator><description>&lt;div&gt;&lt;p&gt;I got a free ticket to Test Automation Day in 2018, just after I'd moved to Rotterdam. I was overwhelmed by the confluence of events: &lt;a href="https://twitter.com/techgirl1908"&gt;Angie Jones&lt;/a&gt; keynoting, &lt;a href="https://twitter.com/ard_kramer"&gt;Ard Kramer&lt;/a&gt; running the show, and meeting &lt;a href="https://twitter.com/amyjph"&gt;Amy Phillips&lt;/a&gt; in real life. (Neither of us were sure it was the first time we'd met because we'd been following each other on Twitter for so long!)&lt;/p&gt;
&lt;p&gt;My most shocking note from Angie's keynote is "clicker, no notes," because of course Angie had her talk down pat. In a talk that anticipated the current, urgent conversation in AI and machine learning, Angie recognized that we can't agree on what human ethics should look like. Figure out who you're advocating for, and tie the bugs back to that business value. You're not going to be able to define all the business requirements up front; expect the unexpected.&lt;/p&gt;
&lt;p&gt;Amy Phillips spoke about how tests in a DevOps environemnt allow you to get fast feedback. Like Agile, this style of working is not about minimizing the pain and struggle in developing software, but rather about bringing that pain forward. DevOps allows us to become aware of problems sooner, so we can act on them sooner. Running more tests is not necessarily better. Do not accept flaky tests. Free yourself from an overreliance on end-to-end tests and tests that cover non-critical paths to get your build time down. Rather than running tests on every commit, improve your monitoring. &lt;/p&gt;
&lt;p&gt;I've got some quotes from other talks and the panel that day: &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;"A tester is someone who believes things can be different." ~ Jerry Weinberg&lt;/li&gt;
&lt;li&gt;"The team was not mature enough to determine priorities."&lt;/li&gt;
&lt;li&gt;"Maintain the relationships you want to build."&lt;/li&gt;
&lt;li&gt;"Are you just doing it because you can?" (regarding UI automation)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I can't tell everybody how welcome and in the right place I felt by being able to jump in this day on short notice. &lt;/p&gt;&lt;/div&gt;</description><category>automation</category><category>conference</category><category>testing</category><guid>https://elizabethzagroba.com/posts/2020/2020-07-13_test_automation_day_2018/</guid><pubDate>Sun, 12 Jul 2020 22:00:00 GMT</pubDate></item><item><title>Start With Belief</title><link>https://elizabethzagroba.com/posts/2020/2020-06-07_start_with_belief/</link><dc:creator>Elizabeth Zagroba</dc:creator><description>&lt;div&gt;&lt;p&gt;Imagine a scenario where you find a software bug. You go to another colleague. They perform the exact same reproduction steps you did. But the bug doesn't happen on their machine. What now? &lt;/p&gt;
&lt;h4&gt;Works on my machine&lt;/h4&gt;
&lt;p&gt;Your colleague may not believe you found a bug, or they may not be sure if you did. They may blame you for doing something you shouldn't have. They may insist that most users have a machine more like theirs than yours, and it doesn't matter if it doesn't work on your machine. They may think it's too much trouble to track down what's happening on your machine, and leave the burden to you to figure it out. They could have a fixed mindset, and think that you, your machine, the software you're running never change. (&lt;a href="https://www.brainpickings.org/2014/01/29/carol-dweck-mindset/"&gt;Read more about fixed vs. growth mindsets in this brilliant Brain Pickings article.&lt;/a&gt;)&lt;/p&gt;
&lt;h4&gt;Does not work on every machine&lt;/h4&gt;
&lt;p&gt;Instead, they could have started with belief. They could commend you for uncovering something they themselves could not. They could be curious about how your machine and software are different from what they have running, and look into how many other users this is affecting. They could pair with you to come up with ideas about how to stop the issue from happening. If they have more access to the underlying systems, they could look into the code and configuration settings. They could have a growth mindset, and think that your machine, the software you're running, and most of all you, can change. &lt;/p&gt;
&lt;h4&gt;Start with belief&lt;/h4&gt;
&lt;p&gt;Now, imagine a different scenario. Imagine someone describes being mistreated by the police. They were doing something that is fully within their rights, and the cops said they weren't allowed to. &lt;/p&gt;
&lt;blockquote&gt;I believe you.&lt;/blockquote&gt;

&lt;p&gt;Start with belief. Do not think that because you've had different interactions with the police, that the police must not treat people in the way you're hearing. Do not think that your individual circumstances, particularly the color of your skin, means that you'll be fine. (&lt;a href="https://www.youtube.com/watch?v=7k0971Hy5eo"&gt;Think more about how racism is fascism applied to a particular category.&lt;/a&gt;) Take the time to shut up, listen, and discover how you can help. Believe that things can change. It starts with belief.&lt;/p&gt;
&lt;p&gt;&lt;span class="img_container" style="display: inline-block;"&gt;&lt;img alt="" src="https://elizabethzagroba.com/images/posts/2020/black_lives_matter.jpg" style="display:block; margin-left: auto; margin-right: auto;" title="Joe Brusky/flickr"&gt;&lt;span class="img_caption" style="display: block; text-align: center;"&gt;Joe Brusky/flickr&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/div&gt;</description><category>debugging</category><category>mindset</category><category>testing</category><guid>https://elizabethzagroba.com/posts/2020/2020-06-07_start_with_belief/</guid><pubDate>Sat, 06 Jun 2020 22:00:00 GMT</pubDate></item><item><title>Trying Out Open API Editors</title><link>https://elizabethzagroba.com/posts/2020/2020-05-30_trying_out_open_api_editors/</link><dc:creator>Elizabeth Zagroba</dc:creator><description>&lt;div&gt;&lt;p&gt;I was editing an Open API with multiple layers of inheritance recently. I &lt;a href="https://elizabethzagroba.com/posts/2020/2020-04-27_errors_you_might_encounter_while_editing_an_open_api_specification/"&gt;kept  uncovering errors&lt;/a&gt; long after I created them because of the way they display in &lt;a href="https://editor.swagger.io"&gt;editor.swagger.io&lt;/a&gt;. &lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=s9u3mXQZbXI"&gt;This great talk from Lorna Jane Mitchell about Open APIs&lt;/a&gt; made me realize how many other tools I could use to edit these specs. There's a whole list at &lt;a href="https://openapi.tools/"&gt;openapi.tools&lt;/a&gt;. During my crafting days, I resolved to try some new editors. I decided to see what it was like to edit the existing complicated spec, and write a spec we were missing for a very simple API (two GET calls).&lt;/p&gt;
&lt;h3&gt;TL;DR&lt;/h3&gt;
&lt;p&gt;I'm going to use the &lt;a href="https://marketplace.visualstudio.com/items?itemName=42Crunch.vscode-openapi"&gt;Visual Studio Code Open API plugin&lt;/a&gt; to write and navigate through our specs. We're rendering our specs with editor.swagger.io, so I'm going to keep running it through there to confirm they appear as expected for our stakeholders.&lt;/p&gt;
&lt;hr&gt;
&lt;h3&gt;Editors&lt;/h3&gt;
&lt;h4&gt;&lt;a href="https://stoplight.io/studio/"&gt;Spotlight Studio&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;Lorna mentioned this one in her talk. It's got a web editor, but I downloaded the Mac client. It's a GUI interface, so rather than writing YAML, it's more like filling out a form. It turns out I would rather write YAML than fill out a form! Good to know.&lt;/p&gt;
&lt;p&gt;The way it organized hierarchy did not suit my mental model for what I was trying to accomplish. I thought about writing a new spec for two GET calls more in a hierarchy (Things both API calls shared. like security &amp;gt; endpoint for the call &amp;gt; parameters). Spotlight Studio grouped adding any new thing into one menu: API, endpoint, parameter, whatever. &lt;/p&gt;
&lt;p&gt;Spotlight Studio has a git integration feature, where you can switch branches within the application. I'd connected it to my remote repo, so it couldn't see the local branch I'd created from my Terminal. When I wanted to save what I had so far (no auto-save??), I found save buried deep inside a menu without a keyboard shortcut to save it. I wasn't interested in changing my workflow to accomodate the tool. &lt;/p&gt;
&lt;p&gt;&lt;span class="img_container" style="display: inline-block;"&gt;&lt;img alt="" src="https://elizabethzagroba.com/images/posts/2020/save-are-you-kidding.png" style="display:block; margin-left: auto; margin-right: auto;" title="Cmd + S it's not that hard"&gt;&lt;span class="img_caption" style="display: block; text-align: center;"&gt;Cmd + S it's not that hard&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;In looking at my existing, complicated API with inheritance, I didn't find a way to see everything in the same view. You had to click through to see inherited sections. Viewing descriptions required a mouse hover. &lt;/p&gt;
&lt;p&gt;The final straw for Spotlight Studio was the error panel. Although thoughfully displayed to be informative without alarming, the line numbers didn't reflect where the issue was. &lt;/p&gt;
&lt;p&gt;Overall: The GUI was getting in my way rather than helping me. Pass.&lt;/p&gt;
&lt;h4&gt;&lt;a href="https://senya.io/"&gt;Senya&lt;/a&gt; for IntelliJ and &lt;a href="https://github.com/RepreZen/KaiZen-OpenAPI-Editor"&gt;Kaizen&lt;/a&gt; for Eclipse&lt;/h4&gt;
&lt;p&gt;I couldn't get either of these installed on my Mac! The instructions were essentially "Install from the marketplace, restart the IDE, and it should just work!" My machine enjoys sending me on fruitless adventures in debugging, but I chose to give up on these tools rather than trying to figure it out.&lt;/p&gt;
&lt;h4&gt;&lt;a href="https://swagger.io/tools/swaggerhub/"&gt;Swagger Hub&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;SwaggerHub came recommended by my colleague &lt;a href="https://twitter.com/reinouts"&gt;Reinout&lt;/a&gt;, so I signed up for a free trial to give it a shot. I'm still not completely sure if this is within the security guidelines our company has for creating accounts and sharing data with third parties, so I deleted the data I'd put in at the end of my session.&lt;/p&gt;
&lt;p&gt;It's a lot like &lt;a href="https://editor.swagger.io"&gt;editor.swagger.io&lt;/a&gt;, but with more bells and whistles.  It does have a separate error panel, which seems like it would be what I want for my big complicated API. But when I was writing my new API in it, the error panel would pop open to remind me about missing fields whenever it decided to auto-save. Not cool. &lt;/p&gt;
&lt;p&gt;Two and a half hours after confirming my email address to use the product, an account manager reached out to me to find out if I had time for a quick phone call. No, I did not, I was in the middle of trying to ignore your pop-ups while writing my damn API spec! Their Twitter person didn't understand my complaint about the errors that appeared in the panel. The one I tweeted about was trying to tell me that request parameters get labelled individually with &lt;code&gt;required: true&lt;/code&gt; or &lt;code&gt;required: false&lt;/code&gt;, while you can throw all the required response parameters in a list. &lt;/p&gt;
&lt;p&gt;&lt;span class="img_container" style="display: inline-block;"&gt;&lt;img alt="" src="https://elizabethzagroba.com/images/posts/2020/twitter-swagger-hub.png" style="display:block; margin-left: auto; margin-right: auto;" title="Memes will not save you"&gt;&lt;span class="img_caption" style="display: block; text-align: center;"&gt;Memes will not save you&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Overall: If I had a license, I'd use SwaggerHub to look at existing APIs, but not to write new ones. I didn't look into using it to run a mock server, but I bet that'd be useful.&lt;/p&gt;
&lt;h4&gt;&lt;a href="https://github.com/OAIE/oaie-sketch"&gt;OAIE Sketch&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;Have you ever used &lt;a href="https://sequencediagram.org/"&gt;sequencediagram.org&lt;/a&gt; to create a UML diagram and thought "What if this looked more 90's?" Well, you're in luck! OAIE Sketch will make you nostalgic for Windows 95. After cloning the github repo and open the .html file locally (whatever works I guess?), you'll see something like this. &lt;/p&gt;
&lt;p&gt;&lt;span class="img_container" style="display: inline-block;"&gt;&lt;img alt="" src="https://elizabethzagroba.com/images/posts/2020/isnt-she-lovely.png" style="display:block; margin-left: auto; margin-right: auto;" title="üòçüòçüòç"&gt;&lt;span class="img_caption" style="display: block; text-align: center;"&gt;üòçüòçüòç&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;I liked the way it was built for you to either update the YAML or the visualization, then decide when to push changes to the other side. But I couldn't figure out how to paste in a spec I had somewhere else and get the visualization to update. &lt;/p&gt;
&lt;p&gt;Overall: Might be a good way to think about shared outputs if it updated?&lt;/p&gt;
&lt;h4&gt;&lt;a href="https://marketplace.visualstudio.com/items?itemName=42Crunch.vscode-openapi"&gt;Visual Studio Code Open API plugin&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;This put me back where I started: the plugin for Visual Studio Code. It's got syntax highlighting. (It made me realize that my export from SwaggerHub added &lt;code&gt;style&lt;/code&gt; and &lt;code&gt;explode&lt;/code&gt; fields to my request parameters! &lt;a href="https://swagger.io/docs/specification/serialization/"&gt;I guess I'll save figuring out if I should keep those for another day.&lt;/a&gt;) It's got a schema, so I can navigate around the spec based on how the things are connected without having to remember line numbers. It's got error messaging that is clear enough without being invasive: red squigglies appear on affected lines and red trangles appear next to the line number on the left. They're small enough to ignore if you're in the middle of writing, but easy enough to find and notice without going on for too long. I'm sticking with this.&lt;/p&gt;&lt;/div&gt;</description><category>api-specs</category><category>apis</category><category>open-api</category><category>swagger</category><category>testing</category><guid>https://elizabethzagroba.com/posts/2020/2020-05-30_trying_out_open_api_editors/</guid><pubDate>Fri, 29 May 2020 22:00:00 GMT</pubDate></item><item><title>If a test falls in a forest...</title><link>https://elizabethzagroba.com/posts/2020/2020-05-24_if_a_test_falls_in_a_forest/</link><dc:creator>Elizabeth Zagroba</dc:creator><description>&lt;div&gt;&lt;p&gt;The saying goes "If a tree falls in a forest and no one is around to hear it, does it make a sound?" I have similar question that shapes the way I think about software testing: If a test is performed but no one takes action on the results, should I have performed it? I think not. &lt;/p&gt;
&lt;p&gt;If the answer to "Who cares?" is "No one," don't perform that test. If you're not going to take action on the results of your testing in the coming hours, days, or weeks, don't perform that test. The world around you will change in the meantime, and the old results will not be as valuable.&lt;/p&gt;
&lt;p&gt;One of the &lt;a href="https://www.agilealliance.org/agile101/12-principles-behind-the-agile-manifesto/"&gt;12 Agile Principles&lt;/a&gt; is simplicity, or maximizing the work not done. Testing on an agile team provides information to help decide what work should picked up in the coming iteration(s). But without meaningful collaboration or feedback, testing is a pile of work for no reason. Work is not meant to produce waste. Save your time and your sanity by thoughtfully analyzing what should not be done, and coming to an agreement with your team about it.&lt;/p&gt;
&lt;p&gt;My team gets scared about the quality of our product and skeptical about how I'm using my time when I describe what I'm not testing, or which automated tests I'm not going to run. "But isn't testing your job?" says the look on their faces. "But then what are you going to do?" is what they manage to say. Rather than capitulating for appearances, to just "look busy," I take this as a challenge to make my exploratory testing and other work I'm doing for the team more visible. &lt;/p&gt;
&lt;h4&gt;Risk-based testing&lt;/h4&gt;
&lt;p&gt;In her &lt;a href="https://www.ministryoftesting.com/dojo/series/testbash-home/lessons/reverse-engineer-your-way-to-adopting-a-risk-based-testing-approach-nishi-grover-garg"&gt;TestBash Home talk&lt;/a&gt;, &lt;a href="https://twitter.com/testwithnishi"&gt;Nishi Grover Garg&lt;/a&gt; asked us to think about estimating impact and likelihood (with possible home intruders as an example). I'd have trouble pinning down our no-estimates team on concrete numbers for undesireable software behavior. &lt;/p&gt;
&lt;p&gt;&lt;span class="img_container" style="display: inline-block;"&gt;&lt;img alt="" src="https://elizabethzagroba.com/images/posts/2020/nishi-impact-likelihood.png" style="display:block; margin-left: auto; margin-right: auto;" title="Slide from Nishi's TestBash Home talk"&gt;&lt;span class="img_caption" style="display: block; text-align: center;"&gt;Slide from Nishi's TestBash Home talk&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;But it does reflect the conversations &lt;a href="http://quality-intelligence.com/documents/DesignBehindthePlan.pdf"&gt;Fiona Charles's test strategy workshop&lt;/a&gt; encouraged me to spark on my team. We do talk about "Yes, this would be a problem, but customers can use this work-around." Or "Yes, we could dive in and investigate whether than could ever happen, but is that more important than picking up the next story?" Being able to identify risks and have thoughtful conversations about their threat to stakeholders allows us to make informed decisions about how we should be spending our time. In testing, we don't always want the most information, we want to discover the best information about the product as efficiently as we can. &lt;/p&gt;
&lt;h4&gt;Examples from my current project&lt;/h4&gt;
&lt;h5&gt;Cross-browser testing&lt;/h5&gt;
&lt;p&gt;We were preparing our web application for a big marketing presentation. The presenter had Firefox as the default browser on their PC. We had a script of the actions they'd perform on stage, and which pages the audience would see. I happened to find bugs on pages we weren't showing, or in the way the scroll bars behaved in Chrome rather than Firefox on my Mac. &lt;/p&gt;
&lt;p&gt;I did not add these issues as bugs in our tracking system, or dig into them further. I knew that they did not pose a risk for the presentation, and a new design would be coming along before customers would potentially use those pages in Chrome on a Mac.s &lt;/p&gt;
&lt;h5&gt;The pipeline&lt;/h5&gt;
&lt;p&gt;We have a pipeline. It runs the tests we've automated at the API and the browser levels against the build in our test environment. I hoped it would inspire the team to think about what the next step could be: getting the tests to run against before merging into our main line, setting up an environment where we're not dependent on the (shared) test environment, looking at the results to see where our application or tests need to change. &lt;/p&gt;
&lt;p&gt;But we don't look at the results. We don't have alerts, we don't open the page during standup, we don't use them as a reference when we're debugging, we don't have a habit of looking at the results. If we do happen to look at the results, we don't take action on it. Building the stability of our feedback loop is not seen as high-priority a task as building new features. &lt;/p&gt;
&lt;p&gt;We don't need to run this pipeline. It's using up AWS resources. Looking at the long line of red X's on the results page only provides alert fatigue. We would be better served by not running these tests. &lt;/p&gt;
&lt;h5&gt;Minimum viable deadline&lt;/h5&gt;
&lt;p&gt;We promised to deliver a feature to a dependent team by a sadline. (A sadline is a deadline without consequences.) In the week before the sadline, three stories were left. On the first story, I found a mistake the developer declared "superficial" when he was lamenting our lack of &lt;a href="https://katrinatester.blogspot.com/2016/12/the-testing-pendulum-finding-balance-in.html"&gt;deep testing&lt;/a&gt;. He decided to review the automated tests I'd written for the second story. He found a couple of use-cases that would require a very particular set of circumstances to occur. I wanted to encourage the behavior of reviewing the tests and thinking about what they're doing more deeply, so I spent the last hour and a half before a holiday weekend automating these two cases. &lt;/p&gt;
&lt;p&gt;I'd drafted some basic automated tests for the third story, but the last feature went relatively unexplored. I should have used my scant time to test the third story more thoroughly instead. The complicated tests for the second story could have waited until next week. While we would be curious about the results, it would not have stopped our delivery of the feature. I should not have written them. &lt;/p&gt;
&lt;p&gt;&lt;span class="img_container" style="display: inline-block;"&gt;&lt;img alt="" src="https://elizabethzagroba.com/images/posts/2020/far-side-tree-falling.jpg" style="display:block; margin-left: auto; margin-right: auto;" title="Far Side cartoon"&gt;&lt;span class="img_caption" style="display: block; text-align: center;"&gt;Far Side cartoon&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;You may be scared to say no to testing things that don't matter, where the performance will not reveal any risks or cause any follow-up actions to take place. It may be tempting to spend a bunch of time testing all the things you can think of, and only reporting on the tests that yield meaningful results. &lt;/p&gt;
&lt;p&gt;But life is not about keeping busy. Make your time at work meaningful by executing meaningful work and declining to do things that aren't important right now.&lt;/p&gt;&lt;/div&gt;</description><category>exploratory-testing</category><category>risk-based-testing</category><category>testbash</category><category>testing</category><guid>https://elizabethzagroba.com/posts/2020/2020-05-24_if_a_test_falls_in_a_forest/</guid><pubDate>Sat, 23 May 2020 22:00:00 GMT</pubDate></item></channel></rss>