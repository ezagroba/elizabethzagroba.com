<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Elizabeth Zagroba: Organizational Anarchist</title><link>https://elizabethzagroba.com/</link><description>Elizabeth Zagroba: Organizational Anarchist</description><atom:link href="https://elizabethzagroba.com/rss.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>© 2022 &lt;a href="mailto:me@elizabethzagroba.com"&gt;Elizabeth Zagroba&lt;/a&gt; Mozilla Public License 2.0</copyright><lastBuildDate>Sun, 27 Feb 2022 18:55:42 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Strengthen Your Code Review Skills</title><link>https://elizabethzagroba.com/posts/2022/02_27_strengthen_your_code_review_skills/</link><dc:creator>Elizabeth Zagroba</dc:creator><description>&lt;p&gt;I spent my first two years at my current company getting my code reviewed and the following almost two years reviewing 3-10 merge requests per week. Our tech stack was in Python, with pytest as our test running, the requests library for API tests, and Selenium for browser tests, all hosted in our company's paid gitlab instance. All that experience shaped how (and whether I) offer feedback on the merge requests I reviewed for members of my own team and neighboring teams working in the same tech stack.&lt;/p&gt;
&lt;h3&gt;Define the relationship.&lt;/h3&gt;
&lt;p&gt;There are power dynamics at play in any relationship at work. For members of my team, they had to have a really good argument to refute one of my "suggestions" because I was their test specialist &lt;em&gt;and&lt;/em&gt; their team lead evaluating their ability to respond to feedback and change their behavior by performance review time. No pressure!&lt;/p&gt;
&lt;p&gt;For members of other teams, they had more power to push back. It could empower them with the knowledge I shared, but they were free to reject it. &lt;/p&gt;
&lt;h3&gt;Focus on what matters.&lt;/h3&gt;
&lt;p&gt;When I review a merge request, I start with the question "what is this code supposed to do?" If it's a merge request for my team, the JIRA ticket number in the title or the branch name would clue me in. For code from other teams, champions would use the description field to explain what the product change was and how the test code supported that. Most merge requests left me guessing a bit. I'd have to read the code contained in the tests to figure out what the test, and ultimately the product, was supposed to do.&lt;/p&gt;
&lt;p&gt;Reading the code also got me thinking about the things I was best equipped to help the code submitter with: maintainability and "what if?" scenarios. As a tester, I could look at a list of tests that create, read, and delete a thing and ask "is update also part of the picture here?" As a code reviewer with a longer tenure at the company, I had a more informed view of whether copy and pasting would work or if a new function was needed.&lt;/p&gt;
&lt;p&gt;We had two linters set up to run on every commit: flake8 covered style enforcement (indentation, blank lines, etc.) and vulture identified unused code. For issues of style that a machine couldn't decide, we had written guidelines to point to. I pointed to these three the most often:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;comments explain why the code is the way it is, not what it does (so code is clearer to read and update)&lt;/li&gt;
&lt;li&gt;setup and teardown should take place outside the test (so pytest reporting tells you there's an &lt;code&gt;error&lt;/code&gt; instead of a &lt;code&gt;failure&lt;/code&gt; when something's off)&lt;/li&gt;
&lt;li&gt;API tests assert the status code before any details about the response body (because the body's not going to have the right stuff in it anyway if the status code is wrong)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I would give feedback about these topics, trying to ask questions to disambiguate my observations from interpretations. I knew that the person who'd written the code had spent more time and thought steeped in the problem than I had. Questions allowed me to assume competence while gathering evidence to the contrary. &lt;/p&gt;
&lt;p&gt;As I read other people's code, I saw lots of weird stuff: stuff I would name differently, stuff I would put in a different order, stuff that took up more or fewer lines than I would have to write the same thing. My experience living in a non-native English speaking culture served me well here: I let it go. Was the test name meaningful to them and their team? Did putting it across a couple more lines help them understand it better? Was it actually a problem with what the code did or just a personal opinion? Did they want to set the constant right before they used it instead of at the top? Go for it! It works, I can understand what they meant, and that should be the threshold. My review was not an opportunity for me to show off my Python skills. I was there to help the code submitter with their tests. I reserved the right to remain silent on unimportant matters. &lt;/p&gt;
&lt;h3&gt;Communicate well.&lt;/h3&gt;
&lt;h4&gt;Praise the good!&lt;/h4&gt;
&lt;p&gt;Notice when people have done something well and praise them for it! Positive reinforcement is the best way to turn up the good on what's already happening in your code base.&lt;/p&gt;
&lt;h4&gt;Right level of abstraction&lt;/h4&gt;
&lt;p&gt;I reviewed merge requests that were 30% done that I mistook for 100% done; conversely I saw at 110% done that I would have killed at 30%. A little [WIP] label in the name of the merge request or bullet list of which tests were still missing helped me offer the code submitter the right kind of feedback at the right time. &lt;/p&gt;
&lt;p&gt;Sometimes, the code isn't the problem, the product is. I've seen a 500 http status code returned for something the user screwed up, which should be in the 400-range. A code comment "Should this be a 400 response?" opened up a more interesting conversation about where the product was in its lifecycle and the code submitter could lobby their team to change the product's behavior.&lt;/p&gt;
&lt;p&gt;If having the conversation about the code isn't the right approach, I tried having &lt;a href="https://elizabethzagroba.com/posts/2021/delivering_information_vs_delivering_meta_information/"&gt;the meta-conversation&lt;/a&gt; instead. "I'm not convinced this API spec is done. Where are you in that process?"&lt;/p&gt;
&lt;p&gt;&lt;span class="img_container" style="display: inline-block;"&gt;&lt;img alt="" src="https://elizabethzagroba.com/images/posts/2022/wtf.png" style="display:block; margin-left: auto; margin-right: auto;" title="Code quality measurement: WTFs/minute"&gt;&lt;span class="img_caption" style="display: block; text-align: center;"&gt;Code quality measurement: WTFs/minute&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h4&gt;Right format&lt;/h4&gt;
&lt;p&gt;Tone is hard in writing. I do prefer writing, because it gives me the opportunity to have several drafts, separating my WTFs-per-minute from what the code submitter receives. I just don't always hit send. Before leaving a comment on a particular line in gitlab, I ask myself: is this the right format? Have I removed any judgy adverbs like "just", "obviously", or "actually"? Would a video call, a Slack message, or a comment on the whole merge request be more likely to be embraced?&lt;/p&gt;
&lt;h4&gt;The receiving&lt;/h4&gt;
&lt;p&gt;One of the many tough things about feedback is that the receiver determines the priority of the feedback. (For all the other tough things about feedback, read &lt;a href="https://app.thestorygraph.com/books/15270135-7360-4e66-b079-4cbd618dfb76"&gt;&lt;em&gt;What Did You Say? The Art of Giving and Receiving Feedback&lt;/em&gt;&lt;/a&gt;.) The code submitter often completely miss what I meant the first time. Even if I thought I'd delivered my feedback as well as I could have, it wasn't always accepted. Everyone extracts different information from the same situation. The feedback that provides the most information can be the hardest to accept.&lt;/p&gt;
&lt;h3&gt;It doesn't have to be like this.&lt;/h3&gt;
&lt;h4&gt;Asynchronous&lt;/h4&gt;
&lt;p&gt;You may have read my first paragraph and asked yourself "why is she doing so many async code reviews?" and you'd be right! The company was scaling at a speed that I was forced to optimize for "number of minutes per day without video calls" over shared understanding.&lt;/p&gt;
&lt;h4&gt;Synchronous&lt;/h4&gt;
&lt;p&gt;Did you know that working in a pair or an ensemble can do all this feedback and knowledge-sharing stuff in a better way? See more about how an ensemble made learning happen in &lt;a href="https://ezagroba.github.io/mob-testing/"&gt;this slide deck&lt;/a&gt;. &lt;/p&gt;
&lt;p&gt;When I was able to, having a conversation helped me make sure that I was giving the right feedback at the right time to the right person. Pairing with the code submitter got not only the mistakes fixed, but also the thought processes behind those mistakes.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://elizabethzagroba.com/images/posts/2022/two_birds.jpg"&gt;&lt;/p&gt;
&lt;h3&gt;Don't take my word for it.&lt;/h3&gt;
&lt;p&gt;I have the benefit of learning from smart people who are also thinking through what code reviews are and what they can be. I have yet to be free at a time when &lt;a href="https://github.com/neontribe/code-reading-club/"&gt;the code reading club&lt;/a&gt; Felinne Hermans started has met, but I look forward to joining sometime in the future. Here is a collection resources that I've already found useful:&lt;/p&gt;
&lt;h4&gt;Videos&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Sarah Mei on &lt;a href="https://www.youtube.com/watch?v=YL-6RCTywbc"&gt;The Power of Agile&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Nina Zakharenko on &lt;a href="https://www.youtube.com/watch?v=6L3ZVLtSeo8"&gt;Code Review Skills for Pythonistas&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Sasha Laundy on &lt;a href="https://www.youtube.com/watch?v=hY14Er6JX2s"&gt;Giving and Getting Technical Help&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;Books&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://app.thestorygraph.com/books/15270135-7360-4e66-b079-4cbd618dfb76"&gt;&lt;em&gt;What Did You Say? The Art of Giving and Receiving Feedback&lt;/em&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://app.thestorygraph.com/books/b15fe452-5b8e-49f5-9e0b-90da490b944c"&gt;&lt;em&gt;Crucial Conversations: Tool for Talking When Stakes Are High&lt;/em&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;Blog posts&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Michaela Greiler on &lt;a href="https://www.michaelagreiler.com/respectful-constructive-code-review-feedback/"&gt;giving respectful code reviews&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Michaela Greiler on &lt;a href="https://www.michaelagreiler.com/accept-code-review-feedback/"&gt;how to handle criticism during code reviews&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Jessica Joy Kerr on &lt;a href="https://jessitron.com/2021/03/27/those-pesky-pull-request-reviews/"&gt;those pesky code reviews&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Angie Jones with &lt;a href="https://angiejones.tech/ten-commandments-code-reviews/"&gt;the 10 commandments of navigating code reviews&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Lucas Rocha on &lt;a href="https://lucasr.org/2011/01/29/micro-commits/"&gt;microcommits&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;Quotes found on Twitter&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;April Wensel on &lt;a href="https://twitter.com/maaretp/status/1024995595973525510"&gt;compassionate code review&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Patricia Aas on the &lt;a href="https://twitter.com/pati_gallardo/status/1373343835330383878"&gt;zero-trust process&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Michaela Greiler on how &lt;a href="https://twitter.com/mgreiler/status/1482247806798733317"&gt;everybody needs an editor&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Michaela Greiler &lt;a href="https://twitter.com/mgreiler/status/1481902327640608770"&gt;thread on the biggest annoyances during code reviews&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Amy Edmondson on &lt;a href="https://twitter.com/AmyCEdmondson/status/1476198824012136460"&gt;psychological safety&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Jerry Weinberg on &lt;a href="https://twitter.com/mstine/status/1481660769456513029"&gt;egoless programming&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Allen Holub on &lt;a href="https://twitter.com/allenholub/status/1491168642586710016"&gt;async code reviews&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Allen Holub on &lt;a href="https://twitter.com/allenholub/status/1482564778149175298"&gt;inspecting quality in&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;Photo by &lt;a href="https://unsplash.com/@robinmathlener?utm_source=unsplash&amp;amp;utm_medium=referral&amp;amp;utm_content=creditCopyText"&gt;Robin Mathlener&lt;/a&gt; on &lt;a href="https://unsplash.com/?utm_source=unsplash&amp;amp;utm_medium=referral&amp;amp;utm_content=creditCopyText"&gt;Unsplash&lt;/a&gt;&lt;/p&gt;</description><category>code-review</category><category>communication</category><category>feedback</category><guid>https://elizabethzagroba.com/posts/2022/02_27_strengthen_your_code_review_skills/</guid><pubDate>Sat, 26 Feb 2022 23:00:00 GMT</pubDate></item><item><title>Not Every Detail Matters</title><link>https://elizabethzagroba.com/posts/2022/02_12_not_every_detail_matters/</link><dc:creator>Elizabeth Zagroba</dc:creator><description>&lt;p&gt;I was looking at a user story for one of the teams I support. The story was about improving a very particular page. Our users do see it. But only for 5-10 minutes per week, if they've started their work early. We deploy this product weekly just before working hours. Deploying currently involves taking the whole product down. Customers can sign up for noticifications so they're reminded about this downtime window. &lt;/p&gt;
&lt;p&gt;The story was to improve the look of a page. People might see it and be confused if the stars aligned and:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;They started work early.&lt;/li&gt;
&lt;li&gt;They hadn't signed up for the notification.&lt;/li&gt;
&lt;li&gt;They hadn't seen the web app with just a logo on it before.&lt;/li&gt;
&lt;li&gt;They didn't try it again in a few minutes. &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So I asked the ticket writer, "This doesn't impact customers much (5-10 minutes per week). Is fixing this worth the effort?"&lt;/p&gt;
&lt;p&gt;They wrote back "I believe in 'Every detail matters.' This particular detail should take very little effort to realize, so my answer on this question is Yes."&lt;/p&gt;
&lt;p&gt;It's possible they're right to pick this ticket up. It was a small enough effort that we might as well do it. If they're wrong, they're the one feeling the pain of explaining the ticket to the team, verifying the fix, deciding what to put in the release notes, etc. It's a safe-to-fail experiment for me as a quality coach. &lt;/p&gt;
&lt;p&gt;But I didn't have the same mindset. I don't believe that we should fix everything we find in our app that violates my expectations. I don't think it's possible to identify one correct set of expectations and priorities that our users will share. I don't think the things that we've already fixed will stay fixed. I don't think it's possible to cover every issue with an automated test. &lt;/p&gt;
&lt;p&gt;I think we need to let go. We need to decide what's important, and focus on that. The details of the downtime page -- the new design, and the time the team spent updating it, and the effort I'd spend having the conversation about it -- none of them mattered too much to me. We need to notice details, and also know when to turn our brains off to being bothered by them. We need to think about the risks of our tests could uncover; our goal isn't 100% test coverage. In short:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Not every detail matters.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;We are limited by our attention, energy, health, meetings on our schedule, time left on this earth. Software is complex enough that it's very unlikely we'll be able to solve every issue we find. The more time we spend solving the unimportant ones, the less time we have left to look for the important ones. Or decide what is important. Or understand our users better to be able to more effectively evaluate the relative importance of such issues. &lt;/p&gt;
&lt;p&gt;Jerry Weinberg cheekily noted the impossibility of this endeavor in his book accurately titled &lt;a href="https://app.thestorygraph.com/books/8ba29269-1843-4ac1-be0c-226752b17937"&gt;&lt;em&gt;Perfect Software and Other Illusions About Testing&lt;/em&gt;&lt;/a&gt;. The Black Box Software Testing Course on Test Design emphasized the need for testers to balance risk vs. coverage. Its focus on &lt;a href="https://www.developsense.com/blog/2010/05/why-we-do-scenario-testing/"&gt;scenario testing&lt;/a&gt; insisted we tie our testing to a user's journey through the software that was:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;coherent&lt;/li&gt;
&lt;li&gt;credible&lt;/li&gt;
&lt;li&gt;motivating&lt;/li&gt;
&lt;li&gt;complex&lt;/li&gt;
&lt;li&gt;easy to evaluate&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I know this is the right approach. It will leave time to build new features and learn new skills. It's what will make it possible for us to feel fulfilled and motivated in our work. &lt;/p&gt;
&lt;p&gt;Now I just need to figure out how to scale this mindset. &lt;/p&gt;</description><category>coaching</category><category>mindset</category><category>risk-based-testing</category><category>testing</category><guid>https://elizabethzagroba.com/posts/2022/02_12_not_every_detail_matters/</guid><pubDate>Fri, 11 Feb 2022 23:00:00 GMT</pubDate></item><item><title>EuroSTAR Testing Voices 2021</title><link>https://elizabethzagroba.com/posts/2022/01_29_eurostar_testing_voices/</link><dc:creator>Elizabeth Zagroba</dc:creator><description>&lt;p&gt;In June of 2021, EuroSTAR ran a &lt;a href="https://huddle.eurostarsoftwaretesting.com/testing-voices-2021/"&gt;free online event&lt;/a&gt;. Having either Maaret Pyhäjärvi and Keith Klain on the program would have been enough to add this to my calendar; having both got me there.&lt;/p&gt;
&lt;hr&gt;
&lt;h3&gt;Maaret Pyhäjärvi: Testing Becoming Harder to be Valuable&lt;/h3&gt;
&lt;p&gt;As usual, Maaret sees a bright and exciting future for her role that I have trouble reconciling with my reality. In Maaret's vision, crowdsourced testers find the obvious bugs. She's left to skim the cream off the milk,  performing the interesting, thoughtful work of understanding a complex system. She and her fellow testers are not repositories for or regurgitators of information. They share testing ideas before they become results or automated tests, with the goal of making others more productive. They tell compelling stories of the unseen: bugs that never happened, testing they never performed.&lt;/p&gt;
&lt;p&gt;Dream big Maaret.&lt;/p&gt;
&lt;h3&gt;Panel: Different Teams, Different Testers&lt;/h3&gt;
&lt;p&gt;Veerle Verhagen hosted this panel. If you're feeling a bit exhausted, I can recommend a small dose of Veerle directly to your brain. These were my top three takeaways:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The best way to skill up automation is to do it on the job.&lt;/li&gt;
&lt;li&gt;You can give assignments back. &lt;/li&gt;
&lt;li&gt;Raise problems even if they're outside the current scope. &lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Keith Klain: Test as Transformation&lt;/h3&gt;
&lt;p&gt;Keith speaks from a position of connecting testing to the business strategy, which is exactly what he recommends we all do. Talk the talk of driving innovation and managing risk to get people's attention and connect what you're doing to the money. Writing a pile of cheap flaky checks (or even consistently passing ones!) may give you a false sense of security that hides the bigger risks. Strive to gather more information to soundly evaluate the risks in your products, enough to understand what would have happened if you hadn't caught it and how to prevent something similar in the future. &lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Thanks to the EuroSTAR team for pulling this together and (not charging for it). &lt;/p&gt;</description><category>conference</category><category>testing</category><guid>https://elizabethzagroba.com/posts/2022/01_29_eurostar_testing_voices/</guid><pubDate>Fri, 28 Jan 2022 23:00:00 GMT</pubDate></item><item><title>This Diagram Asked More Questions Than It Answered</title><link>https://elizabethzagroba.com/posts/2022/01_16_this_diagram_asked_more_questions_than_it_answered/</link><dc:creator>Elizabeth Zagroba</dc:creator><description>&lt;p&gt;I made a diagram that asked more questions than it answered.&lt;/p&gt;
&lt;p&gt;As Quality Lead for the seven engineering teams in my unit, I'm tasked with getting developers to think more holistically. I'm not an expert in any of the individual parts of the product teams are. I aim to have a bird's eye view on the whole, particularly when it comes to the testing we're doing. Each team is thinking about thorough coverage of their part; I'm looking at the through-line across the products.&lt;/p&gt;
&lt;p&gt;So after only a few weeks on the job, when a particular behavior got the software development managers asking me "Did anyone test this end-to-end?" all I could say for sure was "I haven't!" It did get me thinking and asking them though:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;What do you mean when you say end-to-end?&lt;/li&gt;
&lt;li&gt;Did you mean an automated test, or someone trying it at least once manually? &lt;/li&gt;
&lt;li&gt;Is the one path I have in mind the same one you're picturing?&lt;/li&gt;
&lt;li&gt;Is it important to have some type of coverage over every possible path, or can we decide to focus on the risky ones?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I started by drawing what I had in mind. It looked like this. The colored boxes show which team owns the code. The outlined boxes show actions a user could take. &lt;/p&gt;
&lt;p&gt;&lt;span class="img_container" style="display: inline-block;"&gt;&lt;img alt="" src="https://elizabethzagroba.com/images/posts/2022/step1.png" style="display:block; margin-left: auto; margin-right: auto;" title="A humble beginning"&gt;&lt;span class="img_caption" style="display: block; text-align: center;"&gt;A humble beginning&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;I went to it show people all around the department (developers, testers, product, UX, analytics, managers) so they could tell me where I was wrong or needed more detail. (&lt;a href="https://elizabethzagroba.com/posts/2017/2017-08-06_doubt-builds-trust/"&gt;More on how that builds credibility in this post&lt;/a&gt;). &lt;/p&gt;
&lt;p&gt;Each person I showed it to added more boxes, or split existing boxes into more specific actions. Some even added more teams. I approached the teams humbly, acknowledging that though I was being asked about end-to-end testing, I didn't have a good view on what that meant right now. I acknowledged that they were the experts in the their own domains. I'd reviewed roadmaps and documentation to do what I could before I spoke to them so they only had to offer corrections instead of whole explanations. And I thanked them for correcting my ignorance and blind spots as we updated the diagram together. &lt;/p&gt;
&lt;p&gt;To our analytics expert, I said "I get asked a lot about the end-to-end flow, but I'm not sure what that means exactly. Do you have the same problem?" A wave of common struggle and understanding washed over them. &lt;/p&gt;
&lt;p&gt;By the time 15 people had given their perspective, the diagram had exploded into this monstrosity. &lt;/p&gt;
&lt;p&gt;&lt;span class="img_container" style="display: inline-block;"&gt;&lt;img alt="" src="https://elizabethzagroba.com/images/posts/2022/step2.png" style="display:block; margin-left: auto; margin-right: auto;" title="A completely overwhelming mess"&gt;&lt;span class="img_caption" style="display: block; text-align: center;"&gt;A completely overwhelming mess&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This diagram was hard to read. It wasn't clear (to anyone but me) where the entry and exit points where. The key was hard to reference and had too much explanation. At a glance, the main takeaway was "This is complicated." This did live up to one of my goals: get people to see that "test everything end-to-end" is not a straightforward, single path. We wouldn't test every path or promise full coverage from the start (or ever, but that's &lt;a href="https://elizabethzagroba.com/posts/2020/2020-05-24_if_a_test_falls_in_a_forest/"&gt;another conversation&lt;/a&gt;). But we could say: "There's a lot to cover here. Let's choose the most important path to start."&lt;/p&gt;
&lt;p&gt;In showing the diagram to our sales and UX experts, and again acknowledging that this kind of diagramming was more their expertise than mine, I got nudged in the direction of business process modelling notation. I kept my teams and user actions in a way that notation didn't imagine, but putting everything in rows and columns gave my diagram an air of professionalism it didn't have before. &lt;/p&gt;
&lt;p&gt;&lt;span class="img_container" style="display: inline-block;"&gt;&lt;img alt="" src="https://elizabethzagroba.com/images/posts/2022/step3.png" style="display:block; margin-left: auto; margin-right: auto;" title="Something bordering on approachable"&gt;&lt;span class="img_caption" style="display: block; text-align: center;"&gt;Something bordering on approachable&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;A different UX expert said they'd been too overwhelemed to try to process my overwhelming mess of a diagram, but they'd been able to read and learn from this attempt. &lt;/p&gt;
&lt;p&gt;Our software development managers and product experts were the ones asking about the state of end-to-end testing initially. Showing them the diagram got them thinking on the exactly the paths I wanted to trigger: &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Can we have one of these for a different product we're building?&lt;/li&gt;
&lt;li&gt;What would this diagram look like if we only followed one user persona's journey?&lt;/li&gt;
&lt;li&gt;What else might be included in end-to-end if we think outside the scope of the seven engineering teams in our unit?&lt;/li&gt;
&lt;li&gt;How do people buy the product? How are they onboarded?&lt;/li&gt;
&lt;li&gt;How do people learning how to use the product discover these steps you've outlined? How do they know which direction they want to go?&lt;/li&gt;
&lt;li&gt;How do people make decisions at these decision points? How can we gain more insight into how they're doing that?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I think I probably could have helped perform some end-to-end testing with a collection of testers from the three teams I initially identifed in my first diagram, gone back to the managers and proclaimed "yes, we're end-to-end testing." But my job isn't to provide simple answers. It's to get people thinking about the whole, and asking the important questions for themselves. The journey of this diagram did exactly that. &lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Do you find yourself answering questions that you see as misguided? How can you guide people to ask better questions? &lt;/p&gt;</description><category>critical-thinking</category><category>dependencies</category><category>testing</category><guid>https://elizabethzagroba.com/posts/2022/01_16_this_diagram_asked_more_questions_than_it_answered/</guid><pubDate>Sat, 15 Jan 2022 23:00:00 GMT</pubDate></item><item><title>Try Asking Different Questions</title><link>https://elizabethzagroba.com/posts/2021/try_asking_different_questions/</link><dc:creator>Elizabeth Zagroba</dc:creator><description>&lt;figure&gt;&lt;img src="https://elizabethzagroba.com/images/posts/2021/paths.jpeg"&gt;&lt;/figure&gt; &lt;p&gt;I'll never know everything, but I love asking questions to get to know more. Obviously, the same question applied in different contexts will yield different results. A couple questions that worked exactly as I'd wanted with engineering teams really fell flat with UX and product. And a couple &lt;a href="https://elizabethzagroba.com/posts/2021/delivering_information_vs_delivering_meta_information/"&gt;meta-level&lt;/a&gt; questions allowed openings I wouldn't have imagined. &lt;/p&gt;
&lt;h3&gt;When I asked the wrong question&lt;/h3&gt;
&lt;h4&gt;Joining standups&lt;/h4&gt;
&lt;p&gt;Part of the charter for my role is to help improve processes and communication around the department. I'd attended each of the engineering team daily standup meetings, and I wanted to do the same for our designers. My intention was something everyone would agree to, but how I asked made it difficult for the designer to see that:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;"Do designers all meet once a day? I've joined all the other standups; may I join yours?""&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This might have given an impression that I was trying to inflict help or take over, rather than listen and see if my expertise was needed. Even following up with more details about wanting not to duplicate their work didn't seem to clarify my intention. &lt;/p&gt;
&lt;p&gt;Ultimately, speaking to another colleague and starting with my intention helped me understand what space I could be included in. There was a weekly meeting the engineering and product managers attended, where deeper design sessions were planned for that week. I would have never known to ask:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;"Can I attend your weekly meeting with the managers?" &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;because I didn't know there was a weekly meeting. Sharing my intention might have gotten me there sooner.&lt;/p&gt;
&lt;h4&gt;End-to-end flow&lt;/h4&gt;
&lt;p&gt;I'd made a big, complicated diagram of how our users moved through our connected products. I'd imagined it could trigger discussions about all sorts of things, but the two things I wanted it to give the most perspective on were:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;"Are we testing the end-to-end flow?"&lt;/li&gt;
&lt;li&gt;"Are we capturing metrics on the end-to-end flow?"&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Describing the specific actions a user could take and how the products were interconnected showed that, for the development teams, it was hard to know what the ends were. I showed the diagram to most of the development teams and asked the question:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;"What could users do that I haven't captured?"&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;They each thought of things inside the little bubble of their work. But asking the same question to a product owner yielded completely different results: more questions, such as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;"Who are our users? Where do I see them here?"&lt;/li&gt;
&lt;li&gt;"Can we separate out one flow for one use case for one user?"&lt;/li&gt;
&lt;li&gt;"How are people onboarded? Where do our users start?"&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Those last two were completely left of my diagram, since they were outside the scope of what our development teams would build or test for a particular user story. But indeed, the product owners were right that onboarding was part of the end-to-end flow, and thus should be included in how we're looking at the user's journey. &lt;/p&gt;
&lt;p&gt;After a few more discussions, I identified an even better question for the product owners: &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;"How are you thinking about the whole journey a user takes?" &lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;When I asked the right question&lt;/h3&gt;
&lt;h4&gt;Is this the right agenda?&lt;/h4&gt;
&lt;p&gt;I started a meeting with a group of about 12 people with the question:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;"Is this the right agenda?" &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I wanted to make sure the needs that I could see from my position matched what was most important to them. There were five items on the agenda. When we got to the third one, someone determined that there was another way we could approach it, and we changed the agenda right there. Offering the opportunity at the beginning allowed for the team members to take ownership of their time. &lt;/p&gt;
&lt;h4&gt;What fell through the cracks?&lt;/h4&gt;
&lt;p&gt;Retrospectives I've attended and facilitated have often had a "What went wrong?" kind of section. I asked a different question in a session about test strategy, hoping to uncover something slightly different: &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;"What fell through the cracks?" &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Leaving enough silence let people ponder their work in the recent weeks. People named a few product bugs logged to start. After even more silence, some process bugs came to light as well. It was interesting to see how a slight change in the phrasing of the question uncovered things the retrospectives hadn't. &lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;What questions do you tend to ask to the same people in the same way? What might you discover if you change the way you're asking the question? Can you leave more room for thought and contemplation in your conversations?&lt;/p&gt;</description><category>coaching</category><category>communication</category><category>leadership</category><category>mindset</category><guid>https://elizabethzagroba.com/posts/2021/try_asking_different_questions/</guid><pubDate>Thu, 30 Dec 2021 23:00:00 GMT</pubDate></item><item><title>Agile Testing Days 2021</title><link>https://elizabethzagroba.com/posts/2021/agile_testing_days_2021/</link><dc:creator>Elizabeth Zagroba</dc:creator><description>&lt;figure&gt;&lt;img src="https://elizabethzagroba.com/images/posts/2021/unicorn-colors.jpeg"&gt;&lt;/figure&gt; &lt;p&gt;Amazingly, a week physically away from work and present with other human software tester beings was refreshing. And I didn't contract COVID — shoutout to vaccines! Note to self: bring honey, because your voice will be tired from talking through an N95 mask in a loud room. &lt;/p&gt;
&lt;p&gt;Thank you so much &lt;a href="https://agiletestingdays.com/"&gt;Agile Testing Days&lt;/a&gt; for the honor and privilege of serving on your program committee this year, and the straight-up spoiling that comes with attending a conference and not speaking. I've said for years that I enjoy the learning more than the being-in-the-spotlight. This year's edition allowed me to do just that. &lt;/p&gt;
&lt;h4&gt;1. Dagmar Monett - Coming to terms with intelligence in machines&lt;/h4&gt;
&lt;p&gt;Nobody can agree on what intelligence is; it's context-dependent and culture-bound. Human-level AI is not inevitable!&lt;/p&gt;
&lt;h4&gt;2. Klaartje van Zwoll - How therapy made me a better teamplayer&lt;/h4&gt;
&lt;p&gt;All needs are valid! By making your needs specific, it's easier for others to meet them. Journaling can help close the gap between when you experience a thing and when you analyze it. &lt;/p&gt;
&lt;p&gt;Boundaries are high-quality information that people need to love you best. If someone crosses a boundary: specify the behavior, tell them the story of how it made you feel, and describe both the behavior you'd prefer and how that would improve things. &lt;/p&gt;
&lt;p&gt;After you say no, sit in the discomfort of the silence instead of offering excuses. Klaartje also did a great explanation of ask culture vs. guess culture which I've filed as American/Dutch vs. British/Belgian in my head. &lt;/p&gt;
&lt;h4&gt;3. Alex Schladebeck - Unit Testing and TDD from the tester perspective&lt;/h4&gt;
&lt;p&gt;Lots of decisions get made when we're writing code that we never talk about. Writing unit tests for legacy code is hard! Being curious (instead of incredulous) gets you (and your pair) to learn more and have better conversations. &lt;/p&gt;
&lt;h4&gt;4. Maryam Umar - The Power of Coaching for Leading Test Teams&lt;/h4&gt;
&lt;p&gt;Questions Maryam asked the audience that are worth a bit of reflection: &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;What are my career goals?&lt;/li&gt;
&lt;li&gt;What do I want to change personally? &lt;/li&gt;
&lt;li&gt;What do I value? What do I enjoy?&lt;/li&gt;
&lt;li&gt;What outcomes are within my control?&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;5. Gitte Klitgaard - The choice is yours&lt;/h4&gt;
&lt;p&gt;Choices still happen even if they're not active choices. Options expire. When you make a commitment at the last responsible moment, remember the &lt;em&gt;responsible&lt;/em&gt; part. There's space between the stimulus and the response where you can choose how you react. Be the captain of your own ship! We have so much more influence than we think. We can't have everything at once.&lt;/p&gt;
&lt;h4&gt;6. Raj Subrameyer - It is time for Toxic Leaders to come out of their closet&lt;/h4&gt;
&lt;p&gt;Masculinity is toxic. Moving on. &lt;/p&gt;
&lt;h4&gt;7. Jutta Eckstein - Agile Comes with a Responsibility for Sustainability.&lt;/h4&gt;
&lt;p&gt;Software consumes energy: take responsibility. Change your definition of done. Shift the question we ask in and around the product. Testers are the right people to start doing that!&lt;/p&gt;
&lt;h4&gt;8. Zeb Ford-Reitz - What's a Quality Dojo?&lt;/h4&gt;
&lt;p&gt;Zeb's quality dojo: low-risk, low-commitment, high-safety, and long-running. The learning is the product. (The product is the friends you make along the way?) If something is unclear, you need to ask. If you're hoping for a particular outcome, it's not so much an experiment as a bet. &lt;/p&gt;
&lt;h4&gt;9. João Proença - Limitless within our boundaries&lt;/h4&gt;
&lt;p&gt;Having a lot of choices is not necessarily better than only having a few choices. Making decisions all the time will lead to decision fatigue. Embrace the constraints that life gives you. Charters and time-boxes are constraints for exploratory testing. Set up the right constraints to be successful: &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;What is the goal?&lt;/li&gt;
&lt;li&gt;What are the risks you're mitigating?&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;10. Lena Wilberg - Delivering fast &amp;amp; slow&lt;/h4&gt;
&lt;p&gt;Be aware of what is the worst that can happen. Know &lt;a href="https://nordictestingdays.eu/files/files/fiona_charles-10_commandments_for_ethical_testers_keynote_ntd2017.pdf"&gt;Fiona Charles's 10 Commandments for Ethical Software Testers&lt;/a&gt;. Know your personal and career risk tolerance. &lt;/p&gt;
&lt;h4&gt;11. Bruce Hughes - How to be an Ally to Non-binary Folk in Tech&lt;/h4&gt;
&lt;p&gt;Never again should you have to explain or justify your existence. Listening is a beautiful skill. Labels are for communicating with other people. You don't owe anyone your time!&lt;/p&gt;
&lt;h4&gt;12. Lisi Hocke - Growing an Experiment-driven Quality Culture&lt;/h4&gt;
&lt;p&gt;Include a hypotehsis in your experiments. Identify exit criteria, whether or not you succeed. Are the teams ready, eager, and committed? What is the goal? Tackle the unknown, automate the known. Build on people's curiosity. Metrics work locally, temporarily, in context, at the grassroots level. What information do we need for each context? Raise awareness about options. &lt;/p&gt;
&lt;h4&gt;13. Dr. Karen Holland - Food for Thought&lt;/h4&gt;
&lt;p&gt;Mental healthy people can cope with the normal stresses of life. Healthy diets allow us to cope better. Deficiences cannot be fixed by food alone. &lt;/p&gt;
&lt;h4&gt;14. Vera Baum - The Tester's Learning Toolkit&lt;/h4&gt;
&lt;p&gt;Experts produce extraordinary results over a long period of time, but only come about after deliberate practice for four hours a day for ten years. Experts should analyze intuitive reactions. Becoming an expert is not everyone's goal! Only generic knowledge is transferrable. Training wheels are holding you back — you can learn from your failures. Reflection is key. &lt;/p&gt;
&lt;h4&gt;15. Vernon Richards - What does the 'Coach' in 'Quality Coach' mean?&lt;/h4&gt;
&lt;p&gt;Reward structures can promote anti-patterns. Be comfortable with silence. Stay in the present. Notice how they're saying something, and how they're feeling about what they're saying. Decide when to &lt;a href="https://elizabethzagroba.com/posts/2021/give_them_the_fish_then_teach_them_to_fish/"&gt;give them the answer&lt;/a&gt;. &lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;I have the urge to name-drop all my friends here, but also, who cares? This isn't a popularity contest. Just look at &lt;a href="https://twitter.com/search?q=%23agiletd"&gt;Twitter&lt;/a&gt; to see who was there.  I'm grateful to everyone who I was able to give an suspicious eyebrow across the table to, everyone who shared commentary during sessions, everyone whose conversations caused me to skip a session, everyone who patiently waited for me to poorly construct and pronounce Dutch sentences at them, everyone who thought it was fine for me to have a mask on, and most especially, whoever left a piano unlocked. Thank you, and please leave the grand piano unlocked next year. &lt;/p&gt;
&lt;p&gt;I also have the urge to apologize for all the exclamation points in these notes, but I regret to inform you that (1) they do reflect my actual enthusiasm over hearing these message delivered directly from someone's mouth into my ears, and (2) I look forward to the day when our writing can reflect how we'd like to communicate instead of how the patriarchy expects us to. &lt;/p&gt;</description><category>agile-testing-days</category><category>conference</category><category>testing</category><guid>https://elizabethzagroba.com/posts/2021/agile_testing_days_2021/</guid><pubDate>Tue, 28 Dec 2021 10:08:16 GMT</pubDate></item><item><title>TestBash Manchester 2019, The Last One</title><link>https://elizabethzagroba.com/posts/2021/test_bash_manchester_2019/</link><dc:creator>Elizabeth Zagroba</dc:creator><description>&lt;figure&gt;&lt;img src="https://elizabethzagroba.com/images/posts/2021/growthvsfixed.jpeg"&gt;&lt;/figure&gt; &lt;p&gt;I didn't know in September of 2019 that TestBash Manchester was the last TestBash I'd be attending for a while. I've revisited my notes from the workshop Joep Schuurkes and I ran about test reporting several times since then: for a video series, an &lt;a href="https://www.ministryoftesting.com/dojo/series/testing-ask-me-anything"&gt;Ask Me Anything&lt;/a&gt;, a &lt;a href="https://club.ministryoftesting.com/t/ask-me-anything-test-reporting/46827"&gt;forum thread&lt;/a&gt;, a &lt;a href="https://www.ministryoftesting.com/events/essentials-an-introduction-to-reporting-your-testing"&gt;99-minute workshop&lt;/a&gt;, and a &lt;a href="https://elizabethzagroba.com/posts/2021/map_out_your_stakeholders/"&gt;blog post&lt;/a&gt;. I'm just revisiting my notes now from the talks I was able to attend in the couple days after our workshop.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;My notes from Pierre Vincent's talk on observability read like a wishlist of features I'd already been asking for in the app I was testing: unit testing, centralized logging, trace ids for integration debugging, etc. The app was also in a private beta at the time, so data collected from production would be filled with more anomalies than patterns. I'm still discovering how much more influence I have in my new role as Quality Lead to present the impact and influence the improvement of testability features.&lt;/p&gt;
&lt;p&gt;Dan Smart and Yong He spoke about failure. The quote "Hey failors, how's the failing?" captures the essence of their talk: expect failure, and celebrate it, together. I get psyched anytime distinguishes between a fixed and a growth mindset as they did, which I still find best described in &lt;a href="https://www.themarginalian.org/2014/01/29/carol-dweck-mindset/"&gt;this Marginalian (formerly Brain Pickings) piece&lt;/a&gt;. &lt;/p&gt;
&lt;p&gt;I see in my notes from Conor Fitzgerald's talk on Kanban that kan = visual and ban = card. In the two years I spent running a Kanban team in the meantime, I can't remember how many times a week (a day? a minute of standup?) I asked "should we visualize that on the board?" Two of my big legacies on my former team were reinforced by Conor's talk: 1) eliminating of context-switching, and 2) not waiting until the retro to make changes.&lt;/p&gt;
&lt;p&gt;"What does it mean to be responsible for quality?" asks Past Elizabeth to Present Elizabeth from the notes on Gary Fleming's continuous testing talk. It doesn't have a straightforward answer, and exploring this is part of what my job gets to be now. Some of his examples (separating deployment from release, example mapping) are what I get to inspire my whole department to consider as part of their strategy. &lt;/p&gt;
&lt;p&gt;Saskia Coplans's talk on security testing really stuck with me. Her ability to make the unnamable company she consulted for a joke every time she mentioned it was a level of comedy I can only dream of aspiring to in a talk. Familiarity with the STRIDE model and the OWASP Top 10 gives me a leg up in thinking about how to identify and mitigate risk in our software. &lt;/p&gt;
&lt;p&gt;Areti Panou's talk about a deployment pipeline resonates more deeply now, after two years of running and maintaining a pipeline, than it did at the time, when a pipeline was just a glimmer in the eye of a teammate. I held an expectation setting and reaffirmation workshop about one pipeline in my department last week. Areti's expectations that a pipeline should have a clear purpose, failure criteria, and fix deadlines could help fix the bystander effect I've experienced myself. &lt;/p&gt;
&lt;p&gt;The incomparable and unstoppable Lisi Hocke gave a talk about becoming more code-confident that still influences how I approach goals and objectives. Specifically: it's ok to re-evaluate if goals should still apply, and to establish pause or exit criteria to know when to give up. While I can be strong in saying no to what others expect, giving up on something I expect of myself can still be a struggle. &lt;/p&gt;
&lt;p&gt;Bill Matthews's talk on technical risks with AI prompted me to add a "write about these times when you tested a machine learning application" card to the backlog for this blog. I wonder if I'll get around to writing that, since it would be hard to explain it better than Bill did that day. He talked about how training data reinforces stereotypes, and how understanding the domain is crucial to determining what's a random failure vs. what's a systematic failure. &lt;/p&gt;
&lt;p&gt;Louise Gibbs gave a talk on starting her automation journey with a record and playback tool. That's also what got me excited about automation originally, and I'm etnerally grateful to have had the right people steer me towards tests at a lower application level before UI auomation became the only tool in my toolbelt. &lt;/p&gt;
&lt;p&gt;Suman Bala's introduction to Charles Proxy was a memorable one. She'd hooked up her phone to the projected screen without turning her notifications off, so we got to see all the tweets streaming in in real time! If you're just diving into Charles Proxy, the &lt;a href="https://www.ministryoftesting.com/dojo/lessons/breaking-boundaries-using-charles-suman-bala"&gt;recording of this talk&lt;/a&gt; is a great place to start. &lt;/p&gt;
&lt;p&gt;Dominic Kua's talk on bash commands, Wim Selles's talk on Appium, and Henrik Stene's talks on consumer-driven contracts definitely fell into the "these people really know their tool" category. If they were tools I was using, I'd certainly consult their tips and advice. &lt;/p&gt;
&lt;p&gt;Emily Bache's talk shared the ideas from the State of DevOps reports and ultimately the Accelerate book. As a team lead and co-host for a testing ensemble, I was able to help empower people across teams and help build a culture of psychological safety. In my new role as Quality Lead, I'm just starting to collect the DORA metrics to help me decide where I should focus my efforts within the department. &lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;What a memorable group of people, location, and journey it was to TestBash Manchester 2019. I hope the &lt;a href="https://www.ministryoftesting.com/news/testbash-brighton-2022-cancellation-and-testbash-uk"&gt;upcoming TestBash UK&lt;/a&gt; is in the cards for me this coming year, and not only because I still dream about &lt;a href="https://www.mowglistreetfood.com/"&gt;this Indian food&lt;/a&gt; I had on the way in and out of Manchester.&lt;/p&gt;</description><category>conference</category><category>testbash</category><category>testing</category><guid>https://elizabethzagroba.com/posts/2021/test_bash_manchester_2019/</guid><pubDate>Tue, 09 Nov 2021 23:00:00 GMT</pubDate></item><item><title>Map Out Your Stakeholders</title><link>https://elizabethzagroba.com/posts/2021/map_out_your_stakeholders/</link><dc:creator>Elizabeth Zagroba</dc:creator><description>&lt;p&gt;Test reporting is part of a feedback loop. It's the beginning of a conversation, not the end. Knowing who you're having that conversation with allows you to provide those individuals better information for their context. &lt;/p&gt;
&lt;p&gt;If you find a big nasty bug, you might report it differently if your audience is a developer on your team who you work with everyday, a developer on another team who you haven't met, or the Head of Product looking to give an important demo. Reporting on the breath, depth, focus, and impediments to your testing can help your audience guide your upcoming testing. &lt;/p&gt;
&lt;p&gt;Joep Schuurkes and I had an activity as part of workshop on test reporting at TestBash Manchester 2019. I believe he articulated the key idea: if your test reporting depends on your audience, you have to know who your audience is. We had participants map out (with paper and markers) who the stakeholders were for their testing. Some people drew org charts, other drew mind maps.&lt;/p&gt;
&lt;p&gt;In the test reporting workshop I held yesterday, we used a Miro board to map out our stakeholders. As examples, I made an overview of how I was thinking about my recent team. &lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://elizabethzagroba.com/images/posts/2021/stakeholder-mind-map.png"&gt;&lt;/p&gt;
&lt;p&gt;And a version of Dan Ashby's Layers of Influence model, the "shallot" of influence, if you will. &lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://elizabethzagroba.com/images/posts/2021/stakeholder-shallot.png"&gt;&lt;/p&gt;
&lt;p&gt;While these are stated with people's roles, doing this for yourself using people's actual names (or names + roles) will help you think about who they are and what they listening for. &lt;/p&gt;
&lt;p&gt;Identifying the audience for your test report allows you to tailor it to the risks they care about. If you're not sure how to tailor the report, present them with something and find out if that's what they want. Even better, share with them that you're trying to figure out how to make your work most effective for them. &lt;/p&gt;
&lt;p&gt;More things to read:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Other posts on &lt;a href="https://elizabethzagroba.com/categories/reporting/"&gt;test reporting&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://club.ministryoftesting.com/t/ask-me-anything-test-reporting/46827"&gt;Questions left over from an Ask Me Anything on test reporting&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Having the conversation about the conversation, or &lt;a href="https://elizabethzagroba.com/posts/2021/delivering_information_vs_delivering_meta_information/"&gt;delivering meta-information&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description><category>reporting</category><category>risk-based-testing</category><category>testing</category><guid>https://elizabethzagroba.com/posts/2021/map_out_your_stakeholders/</guid><pubDate>Thu, 28 Oct 2021 22:00:00 GMT</pubDate></item><item><title>Unblocking Your Test Strategy</title><link>https://elizabethzagroba.com/posts/2021/unblocking_your_test_strategy/</link><dc:creator>Elizabeth Zagroba</dc:creator><description>&lt;figure&gt;&lt;img src="https://elizabethzagroba.com/images/posts/2021/lightbulb.jpeg"&gt;&lt;/figure&gt; &lt;p&gt;In my new role as Quality Lead for my department, I get to figure out how to infuse everybody's work with "quality", and also figure out what that means exactly. &lt;/p&gt;
&lt;p&gt;One of my colleagues made it easy for me on my second day by coming with a relatively concrete problem: they wanted an acceptance environment for their team. Their team (henceforth: Eager Team) integrated with chronically overloaded and busy team (henceforth: Busy Team), so they wanted an environment where they could test their stuff together before it went into production. They wanted me to help set that up. &lt;/p&gt;
&lt;p&gt;I started my conversation with Eager Team Lead by taking one step back: why did they want this environment? They'd proposed a solution, but I wanted to spend at least a few minutes digging into the problem space with them to hear more about why they wanted this.&lt;/p&gt;
&lt;hr&gt;
&lt;h4&gt;Come up with dream scenario&lt;/h4&gt;
&lt;p&gt;I asked Eager Team Lead what their dream setup would be for their test automation, and why that was the dream.&lt;/p&gt;
&lt;p&gt;Eager Team and Busy Team already had a test environment hooked up to one another. But they both threw whatever they were in the middle of on that environment. Eager Team couldn't count on a stable, usable version of Busy Team's software, and vice versa. Eager Team wanted a place to see what would happen against the production version of Busy Team's code. They wanted to automate all the things they could, and have a place to run that automation. &lt;/p&gt;
&lt;h4&gt;Identify (and confirm they are indeed) constraints&lt;/h4&gt;
&lt;p&gt;Unfortunately Busy Team was busy. They wouldn't be able to make setting up an environment for Eager Team a priority in the next few months. I had that impression, and so did Eager Team Lead. They were, after all, Busy Team. But I wanted to make sure that the busyness of Busy Team was a constraint. I took on the action point to follow up with Boss Person about how we could both (1) check that Busy Team was indeed too busy, and (2) how to get this request on Busy Team's long list for the future.&lt;/p&gt;
&lt;p&gt;I also dispelled one of assumptions underlying Eager Team Lead's dream setup: it was important to test everything, in an automated way, in the ideal environment, or else testing wouldn't be valuable. I explained that it's &lt;a href="https://app.thestorygraph.com/books/8ba29269-1843-4ac1-be0c-226752b17937"&gt;impossible to test everything&lt;/a&gt;. Testing in an automated way would be more likely to reveal known unknowns than the unknown unknowns their team was interested in. And that it wasn't all-or-nothing - every little bit would help.&lt;/p&gt;
&lt;h4&gt;Choose achieveable pieces within constraints&lt;/h4&gt;
&lt;p&gt;Rather than killing the dream, I identified a valuable first step in the direction of the dream. Eager Team would write down, in English to start, 3-5 things that they want to test using both their software and Busy Team's. They'd show those to their product owner to make sure they were things customers cared about. From there, we could look at whether to build automation, and if so, where to run it. There was that test environment already. We had production, could we use feature flags? Could we keep the data only visible to our employees internally? &lt;/p&gt;
&lt;p&gt;I knew I'd hit a nerve when Eager Team Lead said "Oh, we can just start iterating over this!" Because of course, the software itself is not the only thing you can build in an iterative way. Your test automation can also mitigate risk, confirm assumptions, and provide value along the way. &lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;So how'd it go? I confirmed Busy Team's busyness, and got more details on how and when to add this request to their list. I'm following up with Eager Team next week to see where they are in identifying valuable scenarios, or if I should jump in there too. &lt;/p&gt;
&lt;p&gt;But wow, what a feeling to be able to lift the weight of "I need a thing I don't know how to build and don't think I can ever get" off someone's shoulders and replace it with "I know what to do next and it's achievable." &lt;/p&gt;
&lt;p&gt;Stay tuned for more quality leading to come.&lt;/p&gt;</description><category>automation</category><category>coaching</category><category>risk-based-testing</category><category>testing</category><guid>https://elizabethzagroba.com/posts/2021/unblocking_your_test_strategy/</guid><pubDate>Thu, 21 Oct 2021 22:00:00 GMT</pubDate></item><item><title>Cutting People Off</title><link>https://elizabethzagroba.com/posts/2021/cutting_people_off/</link><dc:creator>Elizabeth Zagroba</dc:creator><description>&lt;figure&gt;&lt;img src="https://elizabethzagroba.com/images/posts/2021/shushing.jpeg"&gt;&lt;/figure&gt; &lt;p&gt;Impatience is a virtue. &lt;/p&gt;
&lt;p&gt;If impatience is solely your own, sorry, but you're the asshole. But if impatience is shared, saving your colleagues from a tiresome conversation will make their day. &lt;/p&gt;
&lt;h4&gt;Notice that a topic should come to a close&lt;/h4&gt;
&lt;p&gt;When you listen actively, you'll notice when something has already been said. It is much easier (particularly when remote) to give up, zone out, and think about something else. Don't be that person.&lt;/p&gt;
&lt;p&gt;Engage with your colleagues! Save yourself and others from the perpetual purgatory that is an ineffective meeting. Pay attention. &lt;/p&gt;
&lt;h4&gt;Decide whether you are the right person to close a topic&lt;/h4&gt;
&lt;p&gt;There will be settings where you are the right person to decide if a topic should come to a close: in a small group of relative equals, when you're the appointed facilitator, or you're in some other position of power relative to the individuals or the subject matter. Recognize when you're not in the right position to change what's happening in the moment, and skip to Follow-up for more.&lt;/p&gt;
&lt;p&gt;If the group already has expectations about what is or isn't on topic, your interruption should be enough. If it doesn't, or you want to take this opportunity to set a new one, interrupt with a meta-question. &lt;/p&gt;
&lt;h4&gt;How to deliver this message&lt;/h4&gt;
&lt;p&gt;I'm not always in the best position to decide whether now is the right time for a topic, so I tend to deliver topic-closing messages as questions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;I agree with your point about Thing B, but can we come back to Thing D?&lt;/li&gt;
&lt;li&gt;We agreed that Person A is going to follow-up with Person C, is there anything more that we need to discuss about Thing B right now?&lt;/li&gt;
&lt;li&gt;We could discuss Thing B more in this group, but since we're missing Person C's crucial input, should we?&lt;/li&gt;
&lt;li&gt;I've captured what Person A said here in the notes. Was there anything I missed?&lt;/li&gt;
&lt;li&gt;I think Person A already said Thing B, shall we move on?&lt;/li&gt;
&lt;li&gt;It sounds like we're still discussing Thing B after we just agreed not to, am I understanding that correctly?&lt;/li&gt;
&lt;li&gt;Can we leave it there for now?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If you're not sure if it's the right time for a question, try a meta-question:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Is now the right time to decide if we should keep talking about Thing B?&lt;/li&gt;
&lt;li&gt;Are we going to be able to come to Decision D today?&lt;/li&gt;
&lt;li&gt;Did we decide on a next step towards Thing B, or is that what you were describing?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Give the group a chance to decide, but don't be afraid to hold them to their decision. These are not questions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;We've agreed to that. Let's move on.&lt;/li&gt;
&lt;li&gt;That's all we needed Person A for, let's let them go.&lt;/li&gt;
&lt;li&gt;That's all I have for you, I'll let you go.&lt;/li&gt;
&lt;li&gt;Thank you for your input/time. &lt;/li&gt;
&lt;li&gt;I understand now.&lt;/li&gt;
&lt;li&gt;Got it, thanks.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;Follow-up&lt;/h4&gt;
&lt;p&gt;Get feedback on your behavior. This is how you learn.&lt;/p&gt;
&lt;p&gt;A retrospective or 1-on-1 would be a good place to find out if the balance was right between gathering/sharing information and staying on topic. Asking someone to watch out for this particular behavior ahead of time will allow them to give you better feedback afterwards. &lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;A colleague once declared me the "queen of cutting people off" because I did so very politely. I have a compliment stickie note from "ruling refinement with an iron fist." We should all be so lucky to have our work appreciated this way.&lt;/p&gt;
&lt;p&gt;For more on meta-information, see &lt;a href="https://elizabethzagroba.com/posts/2021/delivering_information_vs_delivering_meta_information/"&gt;this post&lt;/a&gt;. For more on setting agendas and preparing for meetings to make them effective, see &lt;a href="https://j19sch.github.io/slides/atd2020-making-meetings-work.html"&gt;this deck&lt;/a&gt;.&lt;/p&gt;</description><category>communication</category><category>humans</category><category>leadership</category><category>meetings</category><guid>https://elizabethzagroba.com/posts/2021/cutting_people_off/</guid><pubDate>Sun, 17 Oct 2021 22:00:00 GMT</pubDate></item></channel></rss>